[{"authors":["okelet"],"categories":null,"content":"Pues qué contar de mi\u0026hellip; Me llamo Juan Asensio Sánchez, soy natural de un pueblo de Murcia llamado Águilas, y estudié en la Universidad Politécnica de Cartagena Ingeniería Técnica de Telecomunicación, especialidad en Telemática. Estuve estuve trabajando en mis inicios en la ciudad de Murcia, y después como administrador de sistemas Linux en Valladolid, trabajando para OpenInside en la Gerencia Regional de Salud de Castilla y León. En 2014 me vine a Madrid, trabajando durante un tiempo en Everis, principalmente con Amazon Web Services y después en Indra para un importante cliente de telecomunicaciones. Recientemente he vuelto a Everis como Arquitecto Cloud y DevOps.\nSoy fanático del Software Libre, y en mis ratos libres me gusta programar, de todo un poco: Python, Perl, Java, Groovy, etc.\nPuedes contactar conmigo mediante el siguiente formulario.\n   AWS Certified DevOps Engineer - Professional certificate      AWS Certified Solutions Architect - Associate certificate      Google Cloud Certified - Professional Cloud Architect   ","date":-62135596800,"expirydate":-62135596800,"kind":"taxonomy","lang":"es","lastmod":-62135596800,"objectID":"e86e007e05deecb117421510bf305baa","permalink":"https://blog.okelet.com/authors/okelet/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/authors/okelet/","section":"authors","summary":"Pues qué contar de mi\u0026hellip; Me llamo Juan Asensio Sánchez, soy natural de un pueblo de Murcia llamado Águilas, y estudié en la Universidad Politécnica de Cartagena Ingeniería Técnica de Telecomunicación, especialidad en Telemática. Estuve estuve trabajando en mis inicios en la ciudad de Murcia, y después como administrador de sistemas Linux en Valladolid, trabajando para OpenInside en la Gerencia Regional de Salud de Castilla y León. En 2014 me vine a Madrid, trabajando durante un tiempo en Everis, principalmente con Amazon Web Services y después en Indra para un importante cliente de telecomunicaciones.","tags":null,"title":"Juan Asensio","type":"authors"},{"authors":null,"categories":null,"content":"AWS, al listar las instancias de EC2, no devuelve ninguna propiedad que diga cuándo se creó una instancias; esto puede sernos útil en determinadas ocasiones. Podríamos pensar que nos podría valer la propiedad \u0026ldquo;LaunchTime\u0026rdquo;, pero eso en realidad nos indica cuándo se encendió por última vez la instancia, no cuándo se creó.\nAunque directamente este dato no lo proporciona directamente AWS, podemos deducirlo indirectamente a través de otros parámetros:\n La fecha más antigua de vinculación de las tarjetas de red La fecha más antigua de vinculación de los discos  Esto debe ser válido, ya que por ejemplo, la tarjeta de red principal no se puede desvincular de la instancia (You cannot detach a primary network interface from an instance), y su fecha de vinculación permanece siempre igual, aún entre reinicios. También suele ser válido que normalmente, el disco principal de una instancia no suele cambiar, aunque esto no siempre es cierto.\nCon estos datos, podemos lanzar una consulta de la CLI de AWS y mediante el parámetro query (que es una expresión JMESPath), obtener dichos valores:\naws ec2 describe-instances --output table --query 'sort_by(Reservations[].Instances[?State.Name!=`terminated`][].{Name: Tags[?Key==`Name`].Value | [0], InstanceId: InstanceId, CreationTime: min([min(NetworkInterfaces[].Attachment.AttachTime), min(BlockDeviceMappings[].Ebs.AttachTime)]), State: State.Name, InstanceType: InstanceType, PublicIpAddress: PublicIpAddress, PrivateIpAddress: PrivateIpAddress}, \u0026amp;CreationTime)'  Obtendremos una salida similar a la siguiente:\n---------------------------------------------------------------------------------------------------------------------------------------------------------- | DescribeInstances | +--------------------------+----------------------+---------------+----------------------------------+-------------------+-------------------+-----------+ | CreationTime | InstanceId | InstanceType | Name | PrivateIpAddress | PublicIpAddress | State | +--------------------------+----------------------+---------------+----------------------------------+-------------------+-------------------+-----------+ | 2019-05-16T10:33:52.000Z| i-xxxxxxxxxxxxxxxxx | t3a.2xlarge | yyyyyyyyyyyyy | 10.25.z.z | None | running | | 2019-06-03T15:16:31.000Z| i-xxxxxxxxxxxxxxxxx | c5.xlarge | yyyyyyyyyyyyy | 10.25.z.z | None | running | | 2019-07-18T12:05:46.000Z| i-xxxxxxxxxxxxxxxxx | t2.small | yyyyyyyyyyyy | 10.25.z.z | 1.2.3.4 | running | | 2020-01-13T11:08:03.000Z| i-xxxxxxxxxxxxxxxxx | t2.micro | yyyyyyyyyyyy | 10.25.z.z | None | running | | 2020-02-11T15:43:12.000Z| i-xxxxxxxxxxxxxxxxx | c5.large | yyyy | 10.25.z.z | None | running | | 2020-02-11T16:46:14.000Z| i-xxxxxxxxxxxxxxxxx | c5.large | yyyyyyyyy | 10.25.z.z | None | running | | 2020-02-12T08:33:28.000Z| i-xxxxxxxxxxxxxxxxx | t2.micro | yyyyyyyyyyyyy | 10.25.z.z | None | running | | 2020-02-12T14:01:33.000Z| i-xxxxxxxxxxxxxxxxx | c5.large | yyyyyyyyyy | 10.25.z.z | None | running | | 2020-02-13T05:30:34.000Z| i-xxxxxxxxxxxxxxxxx | t3.medium | yyyyyyyyyyyyyyyy | 10.25.z.z | None | running | | 2020-02-13T05:30:34.000Z| i-xxxxxxxxxxxxxxxxx | t3.medium | yyyyyyyyyyyyyy | 10.25.z.z | None | running | | 2020-02-13T05:30:56.000Z| i-xxxxxxxxxxxxxxxxx | t3.medium | yyyyyyyyyyyyyy | 10.25.z.z | None | running | | 2020-02-13T05:30:56.000Z| i-xxxxxxxxxxxxxxxxx | t3.medium | yyyyyyyyy | 10.25.z.z | None | running | +--------------------------+----------------------+---------------+----------------------------------+-------------------+-------------------+-----------+ ","date":1581552000,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1581552000,"objectID":"9854f1f245e4d0755ad2431d5d02244e","permalink":"https://blog.okelet.com/post/2020/02/obtener-la-fecha-de-creacion-de-las-instancias-de-aws-ec2/","publishdate":"2020-02-13T00:00:00Z","relpermalink":"/post/2020/02/obtener-la-fecha-de-creacion-de-las-instancias-de-aws-ec2/","section":"post","summary":"AWS, al listar las instancias de EC2, no devuelve ninguna propiedad que diga cuándo se creó una instancias; esto puede sernos útil en determinadas ocasiones. Podríamos pensar que nos podría valer la propiedad \u0026ldquo;LaunchTime\u0026rdquo;, pero eso en realidad nos indica cuándo se encendió por última vez la instancia, no cuándo se creó.\nAunque directamente este dato no lo proporciona directamente AWS, podemos deducirlo indirectamente a través de otros parámetros:\n La fecha más antigua de vinculación de las tarjetas de red La fecha más antigua de vinculación de los discos  Esto debe ser válido, ya que por ejemplo, la tarjeta de red principal no se puede desvincular de la instancia (You cannot detach a primary network interface from an instance), y su fecha de vinculación permanece siempre igual, aún entre reinicios. También suele ser válido que normalmente, el disco principal de una instancia no suele cambiar, aunque esto no siempre es cierto.\nCon estos datos, podemos lanzar una consulta de la CLI de AWS y mediante el parámetro query (que es una expresión JMESPath), obtener dichos valores:\naws ec2 describe-instances --output table --query 'sort_by(Reservations[].Instances[?State.Name!=`terminated`][].{Name: Tags[?Key==`Name`].Value | [0], InstanceId: InstanceId, CreationTime: min([min(NetworkInterfaces[].Attachment.AttachTime), min(BlockDeviceMappings[].Ebs.AttachTime)]), State: State.Name, InstanceType: InstanceType, PublicIpAddress: PublicIpAddress, PrivateIpAddress: PrivateIpAddress}, \u0026amp;CreationTime)' ","tags":["AWS","EC2","jmespath"],"title":"Obtener la fecha de creación de las instancias de AWS EC2","type":"post"},{"authors":null,"categories":null,"content":"Continuando con un post anterior de cómo probar Ansible AWX con Microk8s (en AWS EC2). Bueno, pues resulta que me creé una imagen personalizada para el contener awx_task para instalar una serie de librerías y comandos que necesitaba para lanzar unos playbooks; el fichero Dockerfile es similar a éste:\nFROM ansible/awx_task:9.1.1 # Switch user to become root USER 0 # Additional software RUN cd \u0026amp;\u0026amp; \\ set -x \u0026amp;\u0026amp; \\ dnf install -y nmap-ncat htop \u0026amp;\u0026amp; \\ dnf clean all # Ansible venv additional dependencies RUN cd \u0026amp;\u0026amp; \\ source /var/lib/awx/venv/ansible/bin/activate \u0026amp;\u0026amp; \\ umask 0022 \u0026amp;\u0026amp; \\ pip install --upgrade pypsrp pysocks \u0026amp;\u0026amp; \\ deactivate # Restore the original user # https://github.com/ansible/awx/blob/devel/installer/roles/image_build/templates/Dockerfile.task.j2 USER 1000  Y me creé un repositorio en AWS ECR. Después generé la imagen y la subí al repositorio (siendo xxxxxxxxxxx el ID de la cuenta de AWS):\n$(aws ecr get-login --no-include-email) docker build --force-rm --pull --no-cache -t xxxxxxxxxxx.dkr.ecr.eu-west-1.amazonaws.com/ansible/awx_task:9.1.1 . docker push xxxxxxxxxxx.dkr.ecr.eu-west-1.amazonaws.com/ansible/awx_task:9.1.1  Tras esto modifiqué el fichero de inventario que usa el instalador de AWX para hacer referencia a la imagen que acabo de subir y crear.\nkubernetes_task_image=xxxxxxxxxxx.dkr.ecr.eu-west-1.amazonaws.com/ansible/awx_task  Pero cuando el cluster de Kubernetes intenta obtener la imagen para crear el pod, se queda en estado ErrImagePull con el mensaje:\nNormal Pulling 2s (x3 over 46s) kubelet, pcjuan Pulling image \u0026quot;xxxxxxxxxxx.dkr.ecr.eu-west-1.amazonaws.com/ansible/awx_task:9.1.1\u0026quot; Warning Failed 2s (x3 over 45s) kubelet, pcjuan Failed to pull image \u0026quot;xxxxxxxxxxx.dkr.ecr.eu-west-1.amazonaws.com/ansible/awx_task:9.1.1\u0026quot;: rpc error: code = Unknown desc = failed to resolve image \u0026quot;xxxxxxxxxxx.dkr.ecr.eu-west-1.amazonaws.com/ansible/awx_task:9.1.1\u0026quot;: no available registry endpoint: unexpected status code https://xxxxxxxxxxx.dkr.ecr.eu-west-1.amazonaws.com/v2/ansible/awx_task/manifests/9.1.1: 401 Unauthorized Warning Failed 2s (x3 over 45s) kubelet, pcjuan Error: ErrImagePull  Esto se debe a que Kubernetes no tiene las credenciales necesarias para acceder al repositorio. Pero después de investigar, es fácil solucionarlo. Lo primero que tenemos que hacer es crear un cronjob en Kubernetes (lo haremos con un crojob porque realmente lo que usa Docker es un token, que tiene caducidad, y hay que renovarlo cada cierto tiempo), para que haga login en el repositorio, y cree una credencial para obtener de forma correcta la imagen; para esto, crearemos un fichero llamado ecr-cred-refresh.yml con el siguiente contenido:\napiVersion: batch/v1beta1 kind: CronJob metadata: name: ecr-cred-helper spec: concurrencyPolicy: Allow schedule: 0 */6 * * * failedJobsHistoryLimit: 1 successfulJobsHistoryLimit: 3 suspend: false jobTemplate: spec: template: spec: containers: - command: - /bin/sh - -c - |- NAMESPACE=awx SERVICE_ACCOUNT=awx ACCOUNT=$(aws sts get-caller-identity --query 'Account' --output text) REGION=$(curl -s http://169.254.169.254/latest/dynamic/instance-identity/document | python -c \u0026quot;import json,sys; print(json.loads(sys.stdin.read())['region'])\u0026quot;) SECRET_NAME=${REGION}-ecr-registry EMAIL=anymail.doesnt.matter@email.com TOKEN=$(aws ecr get-login --region ${REGION} --registry-ids ${ACCOUNT} | cut -d' ' -f6) echo \u0026quot;ENV variables setup done.\u0026quot; kubectl -n ${NAMESPACE} delete secret --ignore-not-found $SECRET_NAME kubectl -n ${NAMESPACE} create secret docker-registry $SECRET_NAME \\ --docker-server=https://${ACCOUNT}.dkr.ecr.${REGION}.amazonaws.com \\ --docker-username=AWS \\ --docker-password=\u0026quot;${TOKEN}\u0026quot; \\ --docker-email=\u0026quot;${EMAIL}\u0026quot; echo \u0026quot;Secret created by name $SECRET_NAME\u0026quot; kubectl -n ${NAMESPACE} patch serviceaccount ${SERVICE_ACCOUNT} -p '{\u0026quot;imagePullSecrets\u0026quot;:[{\u0026quot;name\u0026quot;:\u0026quot;'$SECRET_NAME'\u0026quot;}]}' echo \u0026quot;All done.\u0026quot; image: odaniait/aws-kubectl:latest imagePullPolicy: IfNotPresent name: ecr-cred-helper resources: {} securityContext: capabilities: {} terminationMessagePath: /dev/termination-log terminationMessagePolicy: File dnsPolicy: Default hostNetwork: true restartPolicy: Never schedulerName: default-scheduler securityContext: {} terminationGracePeriodSeconds: 30  En el fichero anterior, dependiendo de nuestra configuración particular, podremos cambiar el valor de las variables NAMESPACE y SERVICE_ACCOUNT, y también especificar manualmente las variables ACCOUNT y REGION si no queremos que el script las auto-detecte porque usamos otras en concreto.\nBásicamente, lo que hace esto, es crear un trabajo de cron, que lanza un contenedor y ejecuta el script en Bash definido en la especificación del pod. En resumen:\n Obtiene las credenciales de acceso a ECR utilizando la cli de AWS Elimina, si existe, el secreto llamado ${REGION}-ecr-registry Lo crea de nuevo, con el token obtenido de ECR Actualiza la service account de AWX indicándole que para obtener las imágenes (imagePullSecrets) tiene usar las credenciales del secreto recién creado  Tras esto, importamos la definición del job en Kubernetes:\nkubectl -n awx apply -f ecr-cred-refresh.yml  Este job se ejecuta cada 6 horas; si queremos forzar la ejecución, podemos hacerlo con los siguientes comandos:\nJOB_NAME=\u0026quot;manual-$(date --utc +%Y%m%d-%H%M%S)\u0026quot; kubectl -n awx create job --from=cronjob/ecr-cred-helper ${JOB_NAME} kubectl -n awx wait --for=condition=complete job.batch/${JOB_NAME} kubectl -n awx logs job.batch/${JOB_NAME}  Pero esto por sí solo no nos vale\u0026hellip; porque ¿dónde le decimos las crendenciales para acceder a AWS (es decir, para que desde dentro del cronjob se pueda hacer aws ecr get-login)? Es decir, el access key y el secret. Para esto, no le pasaremos una key y un secret, sino que crearemos un rol y se lo asignaremos a la instancia EC2 de AWS donde estemos ejecutando Microk8s. El rol debe tener una policy que permita a la instancia acceder al repositorio; podemos usar la policy predefinida AmazonEC2ContainerRegistryReadOnly o crear una manualmente.\nTras crear el rol y la policy, y asignar el rol a la instancia, podemos ejecutar manualmente el cronjob, y ejecutar de nuevo el instalador de AWX, que ya debería obtener la imagen de Docker sin problemas.\nComandos útiles:\n# Ver información de la service account de awx kubectl -n awx describe serviceaccounts awx # Ver información de los secretos (cuándo se actualizó/obtuvo el token por última vez) kubectl -n awx get secrets  Probar manualmente el script:\nkubectl run -i --tty --rm debug --image=odaniait/aws-kubectl:latest --restart=Never -- sh kubectl run --generator=run-pod/v1 -n awx --rm -i --tty compass-tmp --image=odaniait/aws-kubectl:latest -- sh  Referencias:\n  How to configure and use AWS ECR with kubernetes \u0026amp; Rancher2.0 ","date":1579305600,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1579305600,"objectID":"a61051fb6d4191d3285c3e720b0f6c2f","permalink":"https://blog.okelet.com/post/2020/01/configurar-microk8s-para-usar-repositorios-de-aws-ecr/","publishdate":"2020-01-18T00:00:00Z","relpermalink":"/post/2020/01/configurar-microk8s-para-usar-repositorios-de-aws-ecr/","section":"post","summary":"Continuando con un post anterior de cómo probar Ansible AWX con Microk8s (en AWS EC2). Bueno, pues resulta que me creé una imagen personalizada para el contener awx_task para instalar una serie de librerías y comandos que necesitaba para lanzar unos playbooks; el fichero Dockerfile es similar a éste:\nFROM ansible/awx_task:9.1.1 # Switch user to become root USER 0 # Additional software RUN cd \u0026amp;\u0026amp; \\ set -x \u0026amp;\u0026amp; \\ dnf install -y nmap-ncat htop \u0026amp;\u0026amp; \\ dnf clean all # Ansible venv additional dependencies RUN cd \u0026amp;\u0026amp; \\ source /var/lib/awx/venv/ansible/bin/activate \u0026amp;\u0026amp; \\ umask 0022 \u0026amp;\u0026amp; \\ pip install --upgrade pypsrp pysocks \u0026amp;\u0026amp; \\ deactivate # Restore the original user # https://github.com/ansible/awx/blob/devel/installer/roles/image_build/templates/Dockerfile.task.j2 USER 1000 ","tags":["Ansible","AWX","Kubernetes","MicroK8s","ECR"],"title":"Configurar Microk8s para usar repositorios de AWS ECR","type":"post"},{"authors":null,"categories":null,"content":"A la hora de monitorizar estadísticas sobre la ejecución de nuestras funciones Lambda, Cloudwatch ya nos ofrece algunas builtin como:\n Cantidad de throttles Número de invocaciones Número de errores \u0026ldquo;genéricos\u0026rdquo; Duración (media y total)  Pero si queremos ver estadísticas sobre memoria o errores según sean por consumo excesivo de memoria o por timeout, no los tenemos disponibles por defecto.\nPara conseguir información de este tipo de errores, tendremos que recurrir a crear filtros de métricas (metric filters) de los LOGs que deja Lambda en Cloudwatch. Por ejemplo, con el siguiente script, recorremos todas los grupos de LOGs de Lambda (aquellos que empiezan por /aws/lambda/) y creamos unas cuantas métricas en cada uno de ellos, para poder después obtener estadísticas:\n#!/bin/bash # Based on https://gist.github.com/sandfox/337129afa5555af6372d4eae536b20f0 prefix=\u0026quot;/aws/lambda/\u0026quot; for log_group in $(aws logs describe-log-groups --log-group-name-prefix $prefix --query \u0026quot;logGroups[].logGroupName\u0026quot; --output text) ; do fn_name=${log_group#$prefix}; aws logs put-metric-filter \\ --log-group-name \u0026quot;$log_group\u0026quot; \\ --filter-name lambda-memory-usage \\ --filter-pattern '[ x=\u0026quot;REPORT\u0026quot;, x=\u0026quot;RequestId:\u0026quot;, request_id, x=\u0026quot;Duration:\u0026quot;, duration, x=\u0026quot;ms\u0026quot;, x=\u0026quot;Billed\u0026quot;, x=\u0026quot;Duration:\u0026quot;, billed_duration, x=\u0026quot;ms\u0026quot;, x=\u0026quot;Memory\u0026quot;, x=\u0026quot;Size:\u0026quot;, memory_size, x=\u0026quot;MB\u0026quot;, x=\u0026quot;Max\u0026quot;, x=\u0026quot;Memory\u0026quot;, x=\u0026quot;Used:\u0026quot;, memory_used, x=\u0026quot;MB\u0026quot;]' \\ --metric-transformations \u0026quot;metricNamespace=Custom/Lambda,metricName=${fn_name}-MemoryUsed,metricValue=\\$memory_used\u0026quot; aws logs put-metric-filter \\ --log-group-name \u0026quot;$log_group\u0026quot; \\ --filter-name lambda-memory-size \\ --filter-pattern '[ x=\u0026quot;REPORT\u0026quot;, x=\u0026quot;RequestId:\u0026quot;, request_id, x=\u0026quot;Duration:\u0026quot;, duration, x=\u0026quot;ms\u0026quot;, x=\u0026quot;Billed\u0026quot;, x=\u0026quot;Duration:\u0026quot;, billed_duration, x=\u0026quot;ms\u0026quot;, x=\u0026quot;Memory\u0026quot;, x=\u0026quot;Size:\u0026quot;, memory_size, x=\u0026quot;MB\u0026quot;, x=\u0026quot;Max\u0026quot;, x=\u0026quot;Memory\u0026quot;, x=\u0026quot;Used:\u0026quot;, memory_used, x=\u0026quot;MB\u0026quot;]' \\ --metric-transformations \u0026quot;metricNamespace=Custom/Lambda,metricName=${fn_name}-MemorySize,metricValue=\\$memory_size\u0026quot; # Errores que se dan cuando la ejecución se pasa del máximo de memoria permitido aws logs put-metric-filter \\ --log-group-name \u0026quot;${log_group}\u0026quot; \\ --filter-name lambda-memory-errors \\ --filter-pattern 'Process exited before completing request' \\ --metric-transformations \u0026quot;metricNamespace=Custom/Lambda,metricName=${fn_name}-MemoryErrors,metricValue=1,defaultValue=0\u0026quot; # Errores que se dan cuando la ejecución se pasa del máximo de tiempo permitido aws logs put-metric-filter \\ --log-group-name \u0026quot;${log_group}\u0026quot; \\ --filter-name lambda-timeout-errors \\ --filter-pattern 'Task timed out after' \\ --metric-transformations \u0026quot;metricNamespace=Custom/Lambda,metricName=${fn_name}-TimeoutErrors,metricValue=1,defaultValue=0\u0026quot; done  Una vez creados, y pasados cierto tiempo para poder obtener datos, en la sección de métricas de Cloudwatch, tendremos una nueva categoría, Custom/Lambda, donde tendremos el listado de nuevas métricas, por cada función Lambda:\nPodremos seleccionar estas estadísticas para poder visualizar los datos en un gráfico:\nTambién podremos consultar estos datos desde la CLI:\naws cloudwatch get-metric-statistics --namespace Custom/Lambda --metric-name my_function_name-MemoryUsed --start-time $(date --date \u0026quot;1 day ago\u0026quot; +%s) --end-time $(date +%s) --period 300 --statistics Average  { \u0026quot;Label\u0026quot;: \u0026quot;my_function_name-MemoryUsed\u0026quot;, \u0026quot;Datapoints\u0026quot;: [ { \u0026quot;Timestamp\u0026quot;: \u0026quot;2019-08-29T04:10:00Z\u0026quot;, \u0026quot;Average\u0026quot;: 84.32894736842105, \u0026quot;Unit\u0026quot;: \u0026quot;None\u0026quot; }, { \u0026quot;Timestamp\u0026quot;: \u0026quot;2019-08-28T18:10:00Z\u0026quot;, \u0026quot;Average\u0026quot;: 82.94736842105263, \u0026quot;Unit\u0026quot;: \u0026quot;None\u0026quot; }, { \u0026quot;Timestamp\u0026quot;: \u0026quot;2019-08-29T08:10:00Z\u0026quot;, \u0026quot;Average\u0026quot;: 83.72368421052632, \u0026quot;Unit\u0026quot;: \u0026quot;None\u0026quot; }, { \u0026quot;Timestamp\u0026quot;: \u0026quot;2019-08-28T22:10:00Z\u0026quot;, \u0026quot;Average\u0026quot;: 84.63157894736842, \u0026quot;Unit\u0026quot;: \u0026quot;None\u0026quot; }, { \u0026quot;Timestamp\u0026quot;: \u0026quot;2019-08-29T12:10:00Z\u0026quot;, \u0026quot;Average\u0026quot;: 83.59210526315789, \u0026quot;Unit\u0026quot;: \u0026quot;None\u0026quot; }, { \u0026quot;Timestamp\u0026quot;: \u0026quot;2019-08-29T02:10:00Z\u0026quot;, \u0026quot;Average\u0026quot;: 83.17105263157895, \u0026quot;Unit\u0026quot;: \u0026quot;None\u0026quot; }, { \u0026quot;Timestamp\u0026quot;: \u0026quot;2019-08-28T16:10:00Z\u0026quot;, \u0026quot;Average\u0026quot;: 84.35526315789474, \u0026quot;Unit\u0026quot;: \u0026quot;None\u0026quot; }, { \u0026quot;Timestamp\u0026quot;: \u0026quot;2019-08-29T06:10:00Z\u0026quot;, \u0026quot;Average\u0026quot;: 83.85526315789474, \u0026quot;Unit\u0026quot;: \u0026quot;None\u0026quot; }, { \u0026quot;Timestamp\u0026quot;: \u0026quot;2019-08-29T10:10:00Z\u0026quot;, \u0026quot;Average\u0026quot;: 84.48684210526316, \u0026quot;Unit\u0026quot;: \u0026quot;None\u0026quot; }, { \u0026quot;Timestamp\u0026quot;: \u0026quot;2019-08-28T20:10:00Z\u0026quot;, \u0026quot;Average\u0026quot;: 85.0657894736842, \u0026quot;Unit\u0026quot;: \u0026quot;None\u0026quot; }, { \u0026quot;Timestamp\u0026quot;: \u0026quot;2019-08-29T00:10:00Z\u0026quot;, \u0026quot;Average\u0026quot;: 84.97368421052632, \u0026quot;Unit\u0026quot;: \u0026quot;None\u0026quot; }, { \u0026quot;Timestamp\u0026quot;: \u0026quot;2019-08-29T14:10:00Z\u0026quot;, \u0026quot;Average\u0026quot;: 82.57894736842105, \u0026quot;Unit\u0026quot;: \u0026quot;None\u0026quot; } ] } ","date":1567296000,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1567296000,"objectID":"4c3165eb6bc72f212510ede16da05b61","permalink":"https://blog.okelet.com/post/2019/09/monitorizar-memoria-y-errores-de-funciones-lambda/","publishdate":"2019-09-01T00:00:00Z","relpermalink":"/post/2019/09/monitorizar-memoria-y-errores-de-funciones-lambda/","section":"post","summary":"A la hora de monitorizar estadísticas sobre la ejecución de nuestras funciones Lambda, Cloudwatch ya nos ofrece algunas builtin como:\n Cantidad de throttles Número de invocaciones Número de errores \u0026ldquo;genéricos\u0026rdquo; Duración (media y total)  Pero si queremos ver estadísticas sobre memoria o errores según sean por consumo excesivo de memoria o por timeout, no los tenemos disponibles por defecto.\n","tags":["AWS","Lambda","Cloudwatch"],"title":"Monitorizar memoria y errores de funciones Lambda","type":"post"},{"authors":null,"categories":null,"content":"Durante el desarrollo en local de nuestra aplicación en PHP (con el framework CakePHP) solíamos usar el servidor que venía por defecto:\nbin/cake server  El problema de esto (que por debajo usa el servidor embedido de PHP), es que es mono-hilo, es decir, que sirve sólo una petición a la vez, por lo que a veces la carga de la web se hacía bastante pesada.\nPara evitar esto, podemos usar Caddy, que básicamente es un servidor web en un único ejecutable, sin necesidad de instalar un servidor web completo como Apache o nginx, ni tener que gestionar servidores con permisos de root.\nPara poder utilizar Caddy con CakePHP, primero lo instalaremos:\nmkdir -p ~/bin curl -sSfL \u0026quot;https://caddyserver.com/download/linux/amd64?license=personal\u0026amp;telemetry=off\u0026quot; | tar -C ~/bin -zx caddy chmod +x ~/bin/caddy  A continuación, instalaremos el paquete php7.2-cgi, de tal forma que Caddy, cuando arranque, inicie también un proceso PHP que gestionará las peticiones:\nsudo apt install php7.2-cgi  Tras esto, generaremos un fichero de configuración Caddyfile con los siguientes parámetros:\n Levantará el servidor web en http://127.0.0.1:8765 Levanta un servidor php-cgi que escucha en el puerto 9000 Redirigirá todas las peticiones al servidor php-cgi anterior, excepto las que empiecen por:  /static /img /js /css /favicon.ico    :8765 bind 127.0.0.1 root webroot index index.php index.html index.htm gzip fastcgi / 127.0.0.1:9000 php rewrite { if {uri} not_starts_with /static if {uri} not_starts_with /img if {uri} not_starts_with /js if {uri} not_starts_with /css if {uri} not_starts_with /favicon.ico to /index.php?{query} } log stdout errors stdout on startup php-cgi -b 127.0.0.1:9000  Ya sólo nos queda arrancar el entorno de desarrollo (a mi me gusta por limpieza eliminar temporales y cache), ejecutando este comando desde la raíz del proyecto de CakePHP (o similar para otros frameworks):\nrm -Rf tmp/* logs/* \u0026amp;\u0026amp; ~/bin/caddy  Y acceder a nuestra web usando la URL http://127.0.0.1:8765.\n","date":1563148800,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1563148800,"objectID":"6645c199a4ac6c6b318effb7822d32d7","permalink":"https://blog.okelet.com/post/2019/07/usando-caddy-para-desarollo-local-en-php/","publishdate":"2019-07-15T00:00:00Z","relpermalink":"/post/2019/07/usando-caddy-para-desarollo-local-en-php/","section":"post","summary":"Durante el desarrollo en local de nuestra aplicación en PHP (con el framework CakePHP) solíamos usar el servidor que venía por defecto:\nbin/cake server  El problema de esto (que por debajo usa el servidor embedido de PHP), es que es mono-hilo, es decir, que sirve sólo una petición a la vez, por lo que a veces la carga de la web se hacía bastante pesada.\n","tags":null,"title":"Usando caddy para desarollo local en PHP","type":"post"},{"authors":null,"categories":null,"content":"Una cosa que siempre se me olvida y tengo que buscar (como con MySQL): cómo crear un usuario en Postgres, crear una base de datos, y dar permisos al usuario sobre esa base de datos:\npsql -U postgres  create database mydb ENCODING 'UTF8'; create user myuser with encrypted password 'mypass'; grant all privileges on database mydb to myuser;  Nos conectaremos entonces:\npsql -U myuser -W mydb  Comandos rápidos:\n Listar bases de datos: \\l Crear tabla de ejemplo: CREATE TABLE mytable (id INTEGER PRIMARY KEY, name VARCHAR); Listar tablas: \\dt Listar usuarios: \\du  Referencias:\n  Creating user, database and adding access on PostgreSQL  Creating a UTF-8 Database  PostgreSQL: Documentation: 11: psql ","date":1561248000,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1561248000,"objectID":"76b93e522c5aa9e9b3186275acf14c4f","permalink":"https://blog.okelet.com/post/2019/06/crear-usuario-y-base-de-datos-en-postgres-y-dar-permisos/","publishdate":"2019-06-23T00:00:00Z","relpermalink":"/post/2019/06/crear-usuario-y-base-de-datos-en-postgres-y-dar-permisos/","section":"post","summary":"Una cosa que siempre se me olvida y tengo que buscar (como con MySQL): cómo crear un usuario en Postgres, crear una base de datos, y dar permisos al usuario sobre esa base de datos:\npsql -U postgres  create database mydb ENCODING 'UTF8'; create user myuser with encrypted password 'mypass'; grant all privileges on database mydb to myuser; ","tags":["Postgres"],"title":"Crear usuario y base de datos en Postgres y dar permisos","type":"post"},{"authors":null,"categories":null,"content":"AVISO: Post largo (intro a Ansible, AWX, MicroK8s)\nActualización 2020-01-14: Actualizado a Ansible AWX 9.1.1\nAnsible (/ánsibol/) es el gestor de configuración de moda, y por méritos propios. Aunque no es perfecto (en determinadas ocasiones se puede preferir un modelo cliente/servidor en lugar de una conexión SSH ad-hoc), ofrece una buena combinación entre funcionalidad y simplicidad. Siempre y cuando tengamos conectividad SSH con la máquina a gestionar (o no, a través de bastiones), en el caso de equipos Linux, o conectividad WinRM o o PSRP para equipos Windows, podremos realizar infinidad de acciones o tareas sobre las máquinas a gestionar.\nUno de los problemas de Ansible (hablando correctamente, Ansible Engine) es que no tiene una forma de ejecutar de forma automatizada playbooks, para mantener la configuración sincronizada de forma periódica, ejecutar tareas planificadas o incluso auto-provisionar equipos. Aquí es donde entra Ansible Tower, que es la versión con soporte de Ansible AWX, al estilo de lo que Red Hat hace con Wildfly y JBoss. Ansible Tower/AWX en básicamente una API REST con una interfaz web que se comunica con ella. Utilizando esta API, se pueden definir inventarios, credenciales, equipos, plantillas de trabajo, flujos de trabajo, etc. así como asignar permisos por usarios/grupos mediante su sistema RBAC.\nHe de reconocer que al principio cuesta un poco, pero cuando se le pilla el truco, uno se da cuenta de lo potente que es. Pero lo que no me explico es la complejidad de instalación del software. Creo que Red Hat se está empeñando en poner las cosas difíciles a quienes usan sus productos sin suscripción (que al final son los que en gran medida depuran el software, contribuyen de forma gratuita, etc.); en este caso, se nos obliga a hacer una instalación mediante Docker, que aunque está de moda, que lo veo muy bien, creo que deberían dar alternativas (que sí que las dan con la versión con soporte, por lo que impedimentos técnicos no los hay, simplemente es intencionalidad). Para la versión libre (AWX) se soportan los siguientes métodos de instalación:\n Openshift (claramente enfocado a utilizar un stack completo de Red Hat) Docker Compose Kubernetes  En cambio, para Tower, la versión con soporte, es básicamente un script de instalación, que la verdad no he probado, aunque me imagino que lo que hace es provisionar los nodos con el software necesario, a la antigua usanza (no sé si por debajo creará un cluster de K8s u Openshift, o directamente lo hace sobre el sistema operativo).\nBásicamente, la forma de instalación de AWX es crear una serie de contenedores en el orquestador en cuestión (AWX task, AWX web, RabbitMQ, Postgres, Memcached).\nCon ideas de probar AWX para un proyecto interno, empecé a analizar las 3 opciones de instalación; la primera de ellas, Openshift, la descarté desde el principio por ser una tecnología no muy extendida, en favor, en todo caso, de Kubernetes. Ya que esto era una PoC, no quería complicarme mucho con Kubernetes, por lo que empecé a probar con Docker Compose, pero a la hora de escalar, lanzando la instalación en varios nodos, me di cuenta de que el modo de funcionar de AWX requiere un cluster de RabbitMQ, que es difícil de configurar dinámicamente con Docker Compose. Con Kubernetes y su \u0026ldquo;magia\u0026rdquo; hace que el cluster de RabbitMQ se configure y escale automáticamente.\nSiendo mi única opción Kubernetes, no quería montarme un cluster por mi cuenta, ni tener que montar un cluster de EKS, que de base ya son 144$ al mes más los nodos de computación, al final tuve que buscar alternativas más simples.\nMi primera intención fue probar Minikube en mi máquina local, pero cada pod de AWX consume 6 GB de RAM, por lo que mínimo a la MV de Minikube le tenía que dar 7 GB, y teniendo mi portátil 8 GB, murió varias veces en el intento\u0026hellip; Me planteé montar Minikube en una instancia EC2, pero esto sería montar Virtualbox, sobre un entorno ya virtualizado (EC2), y sobre el que correría Kubernetes\u0026hellip; Aunque factible, me parecía un poco engorroso. Así que gracias a mi compañero Roque, que me recordó la existencia de MicroK8s, me decidí a probar.\nPartiendo de una EC2 con Ubuntu 18.04 limpia, estos son los comandos a ejecutar para montar un entorno de Ansible AWX con MicroK8s (forzamos la versión 1.15, ya que AWX no es compatible con una versión mayor, por ahora):\nsudo snap refresh microk8s --channel 1.15/stable sudo snap install helm --channel=2.16/stable --classic (grep \u0026quot;^--allow-privileged$\u0026quot; /var/snap/microk8s/current/args/kube-apiserver \u0026gt; /dev/null) || (echo \u0026quot;--allow-privileged\u0026quot; | sudo tee -a /var/snap/microk8s/current/args/kube-apiserver) (grep \u0026quot;^--allow-privileged$\u0026quot; /var/snap/microk8s/current/args/kubelet \u0026gt; /dev/null) || (echo \u0026quot;--allow-privileged\u0026quot; | sudo tee -a /var/snap/microk8s/current/args/kubelet) sudo microk8s.stop sudo microk8s.start microk8s.enable ingress microk8s.enable dns microk8s.enable storage sudo snap alias microk8s.kubectl kubectl microk8s.config \u0026gt; $HOME/.kube/config helm init   Helm es necesario para instalación de Postgres; si vamos a utilizar una BBDD externa, no es necesario.\nTras esto, ya tenemos el entorno de MicroK8s disponible; ahora nos bajamos AWX y lo configuramos:\n# Actualizar e instalar dependencias mínimas sudo apt update sudo apt upgrade -y sudo apt install -y python3-pip vim pip3 install docker docker-compose --user # Instalar Ansible, necesario para instalar AWX sudo add-apt-repository ppa:ansible/ansible -y sudo apt update sudo apt install -y ansible # Nos bajamos la release 9.1.1 de AWX curl -sLO https://github.com/ansible/awx/archive/9.1.1.tar.gz tar zxf 9.1.1.tar.gz cd awx-9.1.1/installer cp -a inventory{,.original} # Configuramos el fichero de inventario para que use Kubernetes sed -i -e 's/#* *kubernetes_context.*/kubernetes_context=microk8s/' inventory sed -i -e 's/#* *kubernetes_namespace.*/kubernetes_namespace=awx/' inventory # Y lanzamos la instalación ansible-playbook -i inventory install.yml  Variables interesantes en el fichero inventory:\n kubernetes_context: el contexto del cliente de Kubernetes que usaremos para conectarnos al cluster; para MicroK8s, en general será microk8s. kubernetes_namespace: el namespace del cluster de Kubernetes que se usará para crear todos los elementos de AWX; por defecto es awx. kubernetes_deployment_name: es un prefijo que se usa para generar los nombres de los recursos dentro del namespace; por defecto es awx. pg_hostname: es el host remoto donde debemos tener instalado un servidor de Postgres; si esta variable está comentada, el instalador creará un servidor de Postgres en Kubernetes usando Helm; si está definida, se usará el servidor indicado (habrá que configurar adecuadamente el resto de parámetros de conexión a la BBDD: pg_username, pg_password, pg_database, etc.).  También se pueden especificar las siguientes variables para indicar imágenes y versiones alternativas a las oficiales (por ejemplo, si hemos creado unas propias para añadir software, etc.):\n kubernetes_task_version (por defecto: 9.1.1) kubernetes_task_image (por defecto: ansible/awx_task) kubernetes_web_version (por defecto: 9.1.1) kubernetes_web_image (por defecto: ansible/awx_web)  Esto nos creará un namespace llamado awx en MicroK8s, y desplegará en él 2 statefulsets: 1 para Postgres y uno para AWX. Cada statefulset/pod de AWX contiene los siguientes contenedores:\n memcached rabbitmq awx-celery (awx_task) awx-web  Cada vez que se escala el statefulset se crean estos 4 contenedores. Gracias al plugin rabbitmq_peer_discovery_k8s ( aquí se puede ver fichero YAML de configuración) los contenedores de rabbitmq forman un cluster de forma automática.\nPara volver a empezar desde 0, tenemos 2 posibilidades; o bien borrar el namespace:\nkubectl delete namespaces awx  O bien con el comando microk8s.reset, aunque con este comando, frecuentemente se queda \u0026ldquo;colgado\u0026rdquo;:\nmicrok8s.reset  Después del reset, es necesario volver a configurar los complementos (dns, storage, ingress), y configurar el cliente:\nmicrok8s.enable ingress microk8s.enable dns microk8s.enable storage sudo snap alias microk8s.kubectl kubectl microk8s.config \u0026gt; $HOME/.kube/config helm init  Y podemos lanzar de nuevo la instalación:\nansible-playbook -i inventory install.yml  Si por delante del servidor vamos a poner un balanceador (por ejemplo, un ELB o ALB), debemos configurar el ingress de Nginx para que reenvíe las cabeceras X-Forwarded-*:\nkubectl -n default edit configmaps nginx-load-balancer-microk8s-conf  Añadiendo/modificando la sección data con este valor:\ndata: use-forwarded-headers: \u0026quot;true\u0026quot;  Esto es necesario, por ejemplo, si se usa un balanceador con HTTPS, y configuramos la autentificación de Azure, ya que sin el reenvío de estas cabeceras, AWX se cree que vamos por HTTP en lugar de HTTPS, y la URL de callback para el login de Azure se genera incorrectamente.\nUna vez realizados los pasos de la instalación, lo único que nos queda es acceder a la aplicación, usando el puerto 80 de la máquina, por ejemplo, http://localhost, que es donde publica los servicios el ingress controller de nginx.\n","date":1560902400,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1579305600,"objectID":"b53e07b501ece42d340ce533cceef954","permalink":"https://blog.okelet.com/post/2019/06/probando-ansible-awx-con-microk8s/","publishdate":"2019-06-19T00:00:00Z","relpermalink":"/post/2019/06/probando-ansible-awx-con-microk8s/","section":"post","summary":"AVISO: Post largo (intro a Ansible, AWX, MicroK8s)\nActualización 2020-01-14: Actualizado a Ansible AWX 9.1.1\nAnsible (/ánsibol/) es el gestor de configuración de moda, y por méritos propios. Aunque no es perfecto (en determinadas ocasiones se puede preferir un modelo cliente/servidor en lugar de una conexión SSH ad-hoc), ofrece una buena combinación entre funcionalidad y simplicidad. Siempre y cuando tengamos conectividad SSH con la máquina a gestionar (o no, a través de bastiones), en el caso de equipos Linux, o conectividad WinRM o o PSRP para equipos Windows, podremos realizar infinidad de acciones o tareas sobre las máquinas a gestionar.\nUno de los problemas de Ansible (hablando correctamente, Ansible Engine) es que no tiene una forma de ejecutar de forma automatizada playbooks, para mantener la configuración sincronizada de forma periódica, ejecutar tareas planificadas o incluso auto-provisionar equipos. Aquí es donde entra Ansible Tower, que es la versión con soporte de Ansible AWX, al estilo de lo que Red Hat hace con Wildfly y JBoss. Ansible Tower/AWX en básicamente una API REST con una interfaz web que se comunica con ella. Utilizando esta API, se pueden definir inventarios, credenciales, equipos, plantillas de trabajo, flujos de trabajo, etc. así como asignar permisos por usarios/grupos mediante su sistema RBAC.\n","tags":["Ansible","AWX","Kubernetes","MicroK8s"],"title":"Probando Ansible AWX con MicroK8s","type":"post"},{"authors":null,"categories":null,"content":"Es posible que queramos delegar ciertas tareas de administración sobre elementos de Google Cloud a usuarios o departamentos, y que no existan roles predefinidos que hagan exactamente lo que necesitamos. Para eso están los roles personalizados, similar a las políticas de IAM de AWS.\nPor ejemplo, para crear un rol que permita a un usuario apagar, encender y reinicar máquinas virtuales, podemos crear un rol como el siguiente:\ngcloud iam roles create StartStopVms --project ${GOOGLE_CLOUD_PROJECT} \\ --title StartStopVms --description \u0026quot;Can start, stop, suspend, resume and reset VMs\u0026quot; \\ --stage GA --permissions compute.instances.start,compute.instances.stop,compute.instances.suspend,compute.instances.resume,compute.instances.reset  Una vez creado el rol, se lo podemos asignar a un usuario con el siguiente comando:\ngcloud projects add-iam-policy-binding ${GOOGLE_CLOUD_PROJECT} \\ --member user@domain.com \\ --role projects/${GOOGLE_CLOUD_PROJECT}/roles/StartStopVms  En el caso que nos aplica, también sería conveniente dar permisos de sólo lectura (en este ejemplo damos permisos de visor sobre el proyecto completo, aunque se podría afinar más para sólo permitir al acceso a la parte de computación):\ngcloud projects add-iam-policy-binding ${GOOGLE_CLOUD_PROJECT} \\ --member user@domain.com \\ --role roles/viewer  NOTA: La variable GOOGLE_CLOUD_PROJECT se establece automáticamente en la consola de Cloud Shell; si se ejecuta desde otro tipo de consola, se debe establecer manualmente esta variable, cuyo valor es el ID del proyecto sobre el que se están dando permisos.\nReferencias:\n  Understanding IAM custom roles  Creating and managing custom roles ","date":1560816000,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1560816000,"objectID":"e85a0cf6c440bd5e8bf746d53f133567","permalink":"https://blog.okelet.com/post/2019/06/crear-un-rol-personalizado-en-google-cloud-para-encendido-y-apagado-de-maquinas/","publishdate":"2019-06-18T00:00:00Z","relpermalink":"/post/2019/06/crear-un-rol-personalizado-en-google-cloud-para-encendido-y-apagado-de-maquinas/","section":"post","summary":"Es posible que queramos delegar ciertas tareas de administración sobre elementos de Google Cloud a usuarios o departamentos, y que no existan roles predefinidos que hagan exactamente lo que necesitamos. Para eso están los roles personalizados, similar a las políticas de IAM de AWS.\nPor ejemplo, para crear un rol que permita a un usuario apagar, encender y reinicar máquinas virtuales, podemos crear un rol como el siguiente:\ngcloud iam roles create StartStopVms --project ${GOOGLE_CLOUD_PROJECT} \\ --title StartStopVms --description \u0026quot;Can start, stop, suspend, resume and reset VMs\u0026quot; \\ --stage GA --permissions compute.instances.start,compute.instances.stop,compute.instances.suspend,compute.instances.resume,compute.instances.reset ","tags":null,"title":"Crear un rol personalizado en Google Cloud para encendido y apagado de máquinas","type":"post"},{"authors":null,"categories":null,"content":"Existe una medida, llamada índice TIOBE, que valora qué lenguajes de programación son más populares. Los datos salen de los foros de discusión técnicos en donde se observan cuantos internautas cambian impresiones sobre los diferentes lenguajes de programación. Ahora, en junio, el índica TIOBE ha sido publicado y revela que Python es el lenguaje más popular.\n","date":1560729600,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1560729600,"objectID":"374305f4019873b256968784f6f17872","permalink":"https://blog.okelet.com/post/2019/06/python-es-el-lenguaje-mas-popular-hoy-por-hoy/","publishdate":"2019-06-17T00:00:00Z","relpermalink":"/post/2019/06/python-es-el-lenguaje-mas-popular-hoy-por-hoy/","section":"post","summary":"Existe una medida, llamada índice TIOBE, que valora qué lenguajes de programación son más populares. Los datos salen de los foros de discusión técnicos en donde se observan cuantos internautas cambian impresiones sobre los diferentes lenguajes de programación. Ahora, en junio, el índica TIOBE ha sido publicado y revela que Python es el lenguaje más popular.","tags":["Python"],"title":"Python es el lenguaje más popular hoy por hoy","type":"post"},{"authors":null,"categories":null,"content":"Actualización 2019-06-27: Añadida extensión para MongoDB.\nEn el proyecto que estamos desarrollando, tenemos algunas funciones Lambda en Python, con las que no tenemos problemas (por ahora); las dependencias de estas funciones Python las gestionamos con pipenv.\nPero dado que el frontend está desarrollado en PHP, hay veces que necesitamos acceder a determinadas propiedades y funciones desde las funciones Lambda, y nos planteamos migrar o desarrollar nuevas funciones Lambda en PHP. Esto no era posible hasta que hace unos meses, AWS anunció el soporte de custom runtimes, que básicamente consiste en subir el ejecutable con un determinado nombre.\nEn resumen, lo que el post anterior viene a decir es que:\n Tenemos que compilar PHP Tenemos que crear un script llamado bootstrap que será al que llame Lambda; este script será el encargado de conectarse a un endpoint \u0026ldquo;mágico\u0026rdquo; (http://${AWS_LAMBDA_RUNTIME_API}/2018-06-01/runtime/invocation/next), que nos devolverá un JSON con las propiedades de la petición a procesar. Este JSON se lo podemos pasar entonces a una función PHP de nuestra elección.  Un ejemplo de fichero bootstrap se encuentra en este gist:\n El motivo de este post, es que AWS ha publicado una noticia diciendo que va a cambiar la imagen base donde se ejecutan los custom runtimes. Hasta ahora se basaba en una Amazon Linux 2017.03, pero a partir de ahora se van a ejecutar sobre una Amazon Linux 2018.03; esto puede causar que determinados runtimes dejen de funcionar, si están compilados con versiones determinadas de librerías del sistema operativo.\nYa tenía hecho un scriptillo para la versión antigua del runtime, pero como tenía que revisarlo, he decidido \u0026ldquo;ponerlo bonito\u0026rdquo; y publicarlo en el blog. Manos a la obra.\nLo primero que tenemos que hacer es determinar una imagen de Docker válida para la imagen donde se ejecutaría el runtime; en nuestro caso, según la documentación sería una AMI Linux 2018.03, y yendo al Docker Hub, podemos ver la versión de la imagen Docker equivalente.\nUna vez que sabemos la imagen Docker, lanzamos un contenedor:\ndocker run -it --name php-lambda-layer --rm amazonlinux:2018.03.0.20190514 bash  Una vez lanzado, lo primero que haremos será actualizar el sistema e instalar una serie de librerías necesarias para compilar PHP y las dependencias que queremos:\ncd yum update -y yum install autoconf bison gcc gcc-c++ libcurl-devel libxml2-devel openssl-devel git tree zip vim python36 python36-pip libicu-devel unzip diff libpng-devel -y  A continuación, nos bajamos la última versión de PHP y la compilamos, indicando los módulos que queremos incluir:\ncd git clone https://github.com/mongodb/mongo-php-driver.git mongodb cd mongodb git checkout 1.5.5 git submodule update --init cd mkdir ~/php-7-bin curl -sL https://github.com/php/php-src/archive/php-7.3.6.tar.gz | tar -xz cd ~/php-src-php-7.3.6 mv ~/mongodb ext/mongodb ./buildconf --force ./configure --prefix=/root/php-7-bin/ --with-openssl --enable-intl --enable-mbstring --with-pdo-mysql --with-curl --with-zlib --with-gd --enable-bcmath --enable-mongodb --without-pear make make install ~/php-7-bin/bin/php -v ~/php-7-bin/bin/php -m rm -Rf ~/php-7-bin/{include,lib,php,var} rm -Rf ~/php-7-bin/bin/{php-cgi,phpdbg}  Con los parámetros anteriores al compilar, tendremos PHP con los siguientes módulos:\n openssl curl intl mbstring pdo/mysql gd bcmath mongodb zip (https://stackoverflow.com/questions/55394273/building-php-with-libzip-for-aws-lambda-layer)  Tras esto, nos bajamos composer; lo utilizaremos para utilizar la librería guzzlehttp/guzzle para facilitar la manera en la que obtenemos el evento y reportar el estado (y no estar peleando con llamadas a curl):\ncd curl -sS https://getcomposer.org/installer | ~/php-7-bin/bin/php  Lo siguiente sería crear un proyecto de composer e instalar la dependencia mencionada antes; al mismo tiempo, también nos bajamos el fichero bootstrap que será el punto de entrada de nuestro runtime.\nmkdir ~/php-runtime cd ~/php-runtime curl -qL https://gist.github.com/okelet/afe16efea9b89ce90e4690dd752cb4ae/raw \u0026gt; bootstrap chmod 755 bootstrap ~/php-7-bin/bin/php ~/composer.phar require guzzlehttp/guzzle  Por último, lo metemos todo en un fichero ZIP comprimido\nrm -f ~/runtime.zip cd ~/php-7-bin zip -r ~/runtime.zip bin/php cd ~/php-runtime zip -r ~/runtime.zip .  La estructura final de este fichero ZIP es la siguiente:\n├── bin │ └── php ├── bootstrap ├── composer.json ├── composer.lock └── vendor ├── autoload.php ├── composer ├── guzzlehttp ├── psr └── ralouphie  Antes de finalizar el contenedor, desde una shell externa, copiaremos el fichero generado:\ndocker cp php-lambda-layer:/root/runtime.zip .  Ahora subimos la capa (layer) a AWS:\naws lambda publish-layer-version --layer-name php-cake-amzlx201803 --zip-file fileb://runtime.zip --compatible-runtimes provided --region eu-west-1  Lo único que nos quedaría sería subir la función en PHP, indicando que queremos usar un custom runtime y añadirle este layer que hemos subido.\nHay que tener en cuenta que el script bootstrap hace un mapeo entre el directorio src y el namespace App, de modo que si especificamos App\\Lambda\\MyFunction::handler como handler (en la configuración de la función Lambda), buscaría un fichero src/Lambda/MyFunction.php, que debería contener una función estática handler, que aceptaría un único parámetro, que sería el evento; algo así como:\n\u0026lt;?php namespace App\\Lambda; require dirname(__DIR__) . '/../vendor/autoload.php'; class MyFunction { public static function handler($event) { return \u0026quot;Hello \u0026quot; . $event[\u0026quot;name\u0026quot;] . \u0026quot;!; full event is \u0026quot; . json_encode($event); } public static function runner() { return self::handler([ \u0026quot;name\u0026quot; =\u0026gt; \u0026quot;Foo\u0026quot;, \u0026quot;email\u0026quot; =\u0026gt; \u0026quot;no@reply.com\u0026quot;, \u0026quot;groups\u0026quot; =\u0026gt; [ [ \u0026quot;id\u0026quot; =\u0026gt; 1, \u0026quot;name\u0026quot; =\u0026gt; \u0026quot;admin\u0026quot; ], [ \u0026quot;id\u0026quot; =\u0026gt; 8, \u0026quot;name\u0026quot; =\u0026gt; \u0026quot;bar\u0026quot; ] ] ]); } }  La función runner es una función de ayuda para desarrollar en local, de tal forma que podamos indicar dentro de ella el evento al llamar a la función handler, ejecutándolo de la siguiente forma:\nphp -r \u0026quot;require 'src/Lambda/MyFunction.php' ; print_r(call_user_func('App\\Lambda\\MyFunction::runner'));\u0026quot;  Referencias:\n https://aws.amazon.com/blogs/compute/upcoming-updates-to-the-aws-lambda-execution-environment/ https://aws.amazon.com/blogs/compute/updated-timeframe-for-the-upcoming-aws-lambda-and-aws-lambdaedge-execution-environment-update/ https://aws.amazon.com/es/blogs/apn/aws-lambda-custom-runtime-for-php-a-practical-example/ https://developpaper.com/aliyun-centos-7-6-install-php7-3/ ","date":1560211200,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1561593600,"objectID":"b60d1f50a8a3c686ff730bae2e81b8bd","permalink":"https://blog.okelet.com/post/2019/06/crear-custom-runtime-para-php-en-aws-lambda/","publishdate":"2019-06-11T00:00:00Z","relpermalink":"/post/2019/06/crear-custom-runtime-para-php-en-aws-lambda/","section":"post","summary":"Actualización 2019-06-27: Añadida extensión para MongoDB.\nEn el proyecto que estamos desarrollando, tenemos algunas funciones Lambda en Python, con las que no tenemos problemas (por ahora); las dependencias de estas funciones Python las gestionamos con pipenv.\nPero dado que el frontend está desarrollado en PHP, hay veces que necesitamos acceder a determinadas propiedades y funciones desde las funciones Lambda, y nos planteamos migrar o desarrollar nuevas funciones Lambda en PHP. Esto no era posible hasta que hace unos meses, AWS anunció el soporte de custom runtimes, que básicamente consiste en subir el ejecutable con un determinado nombre.\n","tags":["AWS","PHP","Lambda","runtime","custom","layer"],"title":"Crear custom runtime para PHP en AWS Lambda","type":"post"},{"authors":null,"categories":null,"content":"Una cosa que siempre se me olvida y tengo que buscar: cómo crear un usuario en MySQL (o MariaDB o Aurora MySQL), crear una base de datos, y dar permisos al usuario sobre esa base de datos:\nCREATE DATABASE wordpress CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci; CREATE USER 'wpuser'@'localhost' IDENTIFIED BY 'pickApassword'; GRANT ALL PRIVILEGES ON wordpress.* TO 'wpuser'@'localhost'; FLUSH PRIVILEGES; exit  Referencias:\n  Stack Exchange DBA - Create a MySQL database with charset UTF-8 ","date":1560211200,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1560211200,"objectID":"9341de566d28d83a81ce189553cf903d","permalink":"https://blog.okelet.com/post/2019/06/crear-usuario-y-base-de-datos-en-mysql-y-dar-permisos/","publishdate":"2019-06-11T00:00:00Z","relpermalink":"/post/2019/06/crear-usuario-y-base-de-datos-en-mysql-y-dar-permisos/","section":"post","summary":"Una cosa que siempre se me olvida y tengo que buscar: cómo crear un usuario en MySQL (o MariaDB o Aurora MySQL), crear una base de datos, y dar permisos al usuario sobre esa base de datos:\nCREATE DATABASE wordpress CHARACTER SET utf8mb4 COLLATE utf8mb4_unicode_ci; CREATE USER 'wpuser'@'localhost' IDENTIFIED BY 'pickApassword'; GRANT ALL PRIVILEGES ON wordpress.* TO 'wpuser'@'localhost'; FLUSH PRIVILEGES; exit ","tags":["MySQL","MariaDB"],"title":"Crear usuario y base de datos en MySQL y dar permisos","type":"post"},{"authors":null,"categories":null,"content":"Para una aplicación que estamos desarrollando, necesitábamos saber cuándo se van a aplicar los mantenimientos en nuestras instancias de RDS. El problema es que según la documentación de Boto3, el método describe_pending_maintenance_actions devuelve la fecha de aplicación de la actualización en el campo CurrentApplyDate, pero esto siempre viene vacío:\n$ aws rds describe-pending-maintenance-actions  El apaño que hemos hecho, es que cuando detectamos que una instancia de RDS tiene una operación de mantenimiento pendiente, obtenemos la fecha a partir del campo PreferredMaintenanceWindow de la propia instancia.\nfrom pprint import pprint from datetime import datetime, timedelta def parse_rds_maintenance(maintenance_str: str): if not maintenance_str: return None, None start_str, end_str = maintenance_str.split(\u0026quot;-\u0026quot;) start_day, start_hour, start_minute = start_str.split(\u0026quot;:\u0026quot;) end_day, end_hour, end_minute = end_str.split(\u0026quot;:\u0026quot;) start = get_next_date_for(start_day, start_hour, start_minute) end = get_next_date_for(end_day, end_hour, end_minute) return start, end def get_next_date_for(day, hour, minute): days_mappings = { \u0026quot;mon\u0026quot;: 1, \u0026quot;tue\u0026quot;: 2, \u0026quot;wed\u0026quot;: 3, \u0026quot;thu\u0026quot;: 4, \u0026quot;fri\u0026quot;: 5, \u0026quot;sat\u0026quot;: 6, \u0026quot;sun\u0026quot;: 7, } now = datetime.utcnow() day_int = days_mappings.get(day) add_days = 0 if now.isoweekday() \u0026lt; day_int: add_days = day_int - now.isoweekday() elif now.isoweekday() \u0026gt; day_int: add_days = 7 + day_int - now.isoweekday() date = (now + timedelta(days=add_days)).replace(hour=int(hour), minute=int(minute), second=0, microsecond=0) if date \u0026lt; now: date = date + timedelta(days=7) return date if __name__ == '__main__': pprint(parse_rds_maintenance(\u0026quot;tue:07:00-tue:07:30\u0026quot;))  Y esto devuelve (depende de la fecha en la que se ejecute, claro\u0026hellip;):\n(datetime.datetime(2019, 5, 21, 7, 0), datetime.datetime(2019, 5, 21, 7, 30))  ","date":1558310400,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1558310400,"objectID":"4b7be7caed32bfeaf056dcdf41f60638","permalink":"https://blog.okelet.com/post/2019/05/parsear-maintenancewindow-de-rds-en-python/","publishdate":"2019-05-20T00:00:00Z","relpermalink":"/post/2019/05/parsear-maintenancewindow-de-rds-en-python/","section":"post","summary":"Para una aplicación que estamos desarrollando, necesitábamos saber cuándo se van a aplicar los mantenimientos en nuestras instancias de RDS. El problema es que según la documentación de Boto3, el método describe_pending_maintenance_actions devuelve la fecha de aplicación de la actualización en el campo CurrentApplyDate, pero esto siempre viene vacío:\n$ aws rds describe-pending-maintenance-actions ","tags":["AWS","RDS","Python"],"title":"Parsear MaintenanceWindow de RDS en Python","type":"post"},{"authors":null,"categories":null,"content":"","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1546300800,"objectID":"6d99026b9e19e4fa43d5aadf147c7176","permalink":"https://blog.okelet.com/contact/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/contact/","section":"","summary":"Formulario de contacto","tags":null,"title":"Contacto","type":"widget_page"},{"authors":null,"categories":null,"content":"  ProxyChanger: Pequeña utilidad en Go para cambiar el proxy del sistema.  MiniDLNA Indicator: Indicador para usar MiniDLNA como un usuario normal (sin root). [Abandonado] - chphpass (TBD): interfaz web para el cambio de contraseña en Samba4 y Active Directory. [Abandonado] - GCM Connection Manager (TBD): gestor de conexiones SSH (fork de Gnome Connection Manager)  ","date":1546300800,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1546300800,"objectID":"6087c0ef875554f4409ac52928d79279","permalink":"https://blog.okelet.com/projects/","publishdate":"2019-01-01T00:00:00Z","relpermalink":"/projects/","section":"","summary":"  ProxyChanger: Pequeña utilidad en Go para cambiar el proxy del sistema.  MiniDLNA Indicator: Indicador para usar MiniDLNA como un usuario normal (sin root). [Abandonado] - chphpass (TBD): interfaz web para el cambio de contraseña en Samba4 y Active Directory. [Abandonado] - GCM Connection Manager (TBD): gestor de conexiones SSH (fork de Gnome Connection Manager)  ","tags":null,"title":"Proyectos...","type":"page"},{"authors":null,"categories":null,"content":"Instalaremos Cygwin de la forma habitual; simplemente nos aseguraremos de seleccionar el paquete wget en la ventana de selección de paquetes, o bien lanzar el instalador con el siguiente comando:\nsetup-x86_64.exe --download --site http://mirrors.fe.up.pt/pub/cygwin/ --upgrade-also --no-admin --root %LOCALAPPDATA%/cygwin64 --packages wget\r Tras esto, instalamos apt-cyg, que es un gestor de paquetes de Cygwin, y una serie de paquetes que considero imprescindibles:\nwget -q https://rawgit.com/transcode-open/apt-cyg/master/apt-cyg\rinstall apt-cyg /bin\rapt-cyg install curl gcc-core make nano vim git openssh python python-crypto python-paramiko python-setuptools python-jinja2 python-yaml\r Por último, instalamos Ansible desde PyPi (se podría instalar ansible directamente con easy_install, pero prefiero hacerlo con pip, y así ya lo tengo para el futuro):\neasy_install-2.7 pip\rpip install ansible\r Para probar el correcto funcionamiento:\nansible --version\ransible -i localhost, -c local all -m ping\ransible -i localhost, -c local all -m setup\r ","date":1461974400,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1461974400,"objectID":"a9bd337a4f8a934be4edae132782f05a","permalink":"https://blog.okelet.com/post/2016/04/instalar-ansible-en-cygwin/","publishdate":"2016-04-30T00:00:00Z","relpermalink":"/post/2016/04/instalar-ansible-en-cygwin/","section":"post","summary":"Instalaremos Cygwin de la forma habitual; simplemente nos aseguraremos de seleccionar el paquete wget en la ventana de selección de paquetes, o bien lanzar el instalador con el siguiente comando:\nsetup-x86_64.exe --download --site http://mirrors.fe.up.pt/pub/cygwin/ --upgrade-also --no-admin --root %LOCALAPPDATA%/cygwin64 --packages wget\r","tags":["Linux","Cygwin","Ansible"],"title":"Instalar Ansible en Cygwin","type":"post"},{"authors":null,"categories":null,"content":"Normalmente, en Bash, redirigimos la salida estándar a un fichero o la entrada de otro comando con la siguiente sintaxis:\nls -l mifichero.txt noexiste \u0026gt; salida.txt ls -l mifichero.txt noexiste | tee salida.txt  Y la salida de error así:\nls -l mifichero.txt noexiste 2\u0026gt; salida.txt ls -l mifichero.txt noexiste 2\u0026gt;\u0026amp;1 \u0026gt;/dev/null | tee salida.txt  Podemos redirigir la salida estándar y de error al mismo tiempo:\nls -l mifichero.txt noexiste \u0026gt; salida.txt 2\u0026gt;\u0026amp;1 ls -l mifichero.txt noexiste 2\u0026gt;\u0026amp;1 | tee salida.txt  O de esta otra forma más simplificada (\u0026amp;| no funciona):\nls -l mifichero.txt noexiste \u0026amp;\u0026gt; salida.txt ","date":1461110400,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1461110400,"objectID":"0b4e13e667371a8bb0cd88b8c54b8d36","permalink":"https://blog.okelet.com/post/2016/04/enviar-salida-estandar-y-de-error-al-mismo-tiempo/","publishdate":"2016-04-20T00:00:00Z","relpermalink":"/post/2016/04/enviar-salida-estandar-y-de-error-al-mismo-tiempo/","section":"post","summary":"Normalmente, en Bash, redirigimos la salida estándar a un fichero o la entrada de otro comando con la siguiente sintaxis:\nls -l mifichero.txt noexiste \u0026gt; salida.txt ls -l mifichero.txt noexiste | tee salida.txt  Y la salida de error así:\nls -l mifichero.txt noexiste 2\u0026gt; salida.txt ls -l mifichero.txt noexiste 2\u0026gt;\u0026amp;1 \u0026gt;/dev/null | tee salida.txt  Podemos redirigir la salida estándar y de error al mismo tiempo:\nls -l mifichero.txt noexiste \u0026gt; salida.txt 2\u0026gt;\u0026amp;1 ls -l mifichero.txt noexiste 2\u0026gt;\u0026amp;1 | tee salida.txt  O de esta otra forma más simplificada (\u0026amp;| no funciona):\nls -l mifichero.txt noexiste \u0026amp;\u0026gt; salida.txt ","tags":["Linux","Bash"],"title":"Enviar salida éstandar y de error al mismo tiempo","type":"post"},{"authors":null,"categories":null,"content":"Pues eso, la forma más corta y simple de crear o vaciar un archivo en Linux:\n\u0026gt; fichero  Otras formas:\ntouch fichero echo \u0026quot;\u0026quot; \u0026gt; fichero cat /dev/null \u0026gt; fichero ","date":1461024000,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1461024000,"objectID":"faeb5cdc2a0f9149ab8ed414c28647e6","permalink":"https://blog.okelet.com/post/2016/04/la-forma-mas-corta-y-simple-de-crear-o-vaciar-un-archivo-en-linux/","publishdate":"2016-04-19T00:00:00Z","relpermalink":"/post/2016/04/la-forma-mas-corta-y-simple-de-crear-o-vaciar-un-archivo-en-linux/","section":"post","summary":"Pues eso, la forma más corta y simple de crear o vaciar un archivo en Linux:\n\u0026gt; fichero  Otras formas:\ntouch fichero echo \u0026quot;\u0026quot; \u0026gt; fichero cat /dev/null \u0026gt; fichero ","tags":["Linux","Bash"],"title":"La forma más corta y simple de crear o vaciar un archivo en Linux","type":"post"},{"authors":null,"categories":null,"content":"Cuando se instala Ansible, por defecto va a usar la configuración y fichero de hosts del directorio /etc/ansible. Si queremos poder ejecutar Ansible sin necesidad de estar tocando continuamente ficheros de configuración con root, podemos crear un archivo de configuración y otro de hosts en nuestro directorio personal, que prevalecerán sobre los que hay en /etc/ansible.\nPara ello, crearemos el fichero de configuración ~/.ansible.cfg con el siguiente contenido:\n[defaults] inventory = ~/.ansible_hosts  Y tras esto, crear el archivo de hosts al que hacemos referencia:\nlocalhost  Para probar que Ansible está cogiendo esta configuración, ejecutaremos el siguiente comando (muestra los facts del servidor que cumplan el filtro ansible_eth[0-2]):\nansible localhost -m setup -a 'filter=ansible_eth[0-2]' ","date":1459814400,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1459814400,"objectID":"16273f153d0140a0dc390e25d99b5975","permalink":"https://blog.okelet.com/post/2016/04/ansible-sin-root/","publishdate":"2016-04-05T00:00:00Z","relpermalink":"/post/2016/04/ansible-sin-root/","section":"post","summary":"Cuando se instala Ansible, por defecto va a usar la configuración y fichero de hosts del directorio /etc/ansible. Si queremos poder ejecutar Ansible sin necesidad de estar tocando continuamente ficheros de configuración con root, podemos crear un archivo de configuración y otro de hosts en nuestro directorio personal, que prevalecerán sobre los que hay en /etc/ansible.\nPara ello, crearemos el fichero de configuración ~/.ansible.cfg con el siguiente contenido:\n[defaults] inventory = ~/.ansible_hosts  Y tras esto, crear el archivo de hosts al que hacemos referencia:\nlocalhost  Para probar que Ansible está cogiendo esta configuración, ejecutaremos el siguiente comando (muestra los facts del servidor que cumplan el filtro ansible_eth[0-2]):\nansible localhost -m setup -a 'filter=ansible_eth[0-2]' ","tags":null,"title":"Ansible sin root","type":"post"},{"authors":null,"categories":null,"content":"Trasteando con Openstack, con ganas desde hace tiempo, y después de la Mini-Conf del grupo MAD for OpenStack, me animé a probarlo usando PackStack, que te lo configura todo en una única máquina (no tengo claro si se puede considerar una instalación productiva o sólo para pruebas), aunque luego puedes ir añadiendo nodos adicionales. Dado que no tengo acceso a ningún host físico, instalé un RH 7.2 (también vale Fedora o CentOS) en una máquina virtual de VMware (el rendimiento dependerá en gran medida si se tiene habilitado o no la  nested virtualization). Empecé con una máquina con 2 procesadores y 2 GB de RAM, pero enseguida me di cuenta que se quedaba muy corta, incluso sin ninguna instancia arrancada. La versión final tiene 8 procesadores y 8 GB de RAM.\nEl siguiente problema que me surgió es que me daba un error al instalar el paquete de Cinder, ya que le faltaba una dependencia. Y no me lo explicaba, porque esa dependencia está en el repositorio de EPEL, que lo tenía configurado y habilitado. Después de varias pruebas, me di cuenta que el instalador deshabilita ese repositorio, y hay que forzar a que lo utilice con un parámetro adicional (--use-epel=y).\nDespués, me daba fallo al descargar la imagen de CirrOS para ponerla como disponible para nuevas instancias, y es que esta imagen se la descarga de Internet, así que tenía que utilizar el proxy, por lo que me creé un /etc/profile.d/proxy.sh donde se establecía, pero el proxy hacía que fallaran las peticiones REST que se realizan durante la instalación para registrar componentes, configuración, etc. Así que encontré una opción que lo que hace es utilizar una imagen descargada localmente, en lugar de descargársela de Internet. Por tanto, borré el profile.d del proxy, y me bajé la imagen a mano:\nexport https_proxy=http://mi.proxy:8080 wget --no-check-certificate https://download.cirros-cloud.net/0.3.4/cirros-0.3.4-x86_64-disk.img  Una vez hecho esto, hay que tener configurado el proxy en Yum, ya que se descarga bastantes paquetes de Internet. Una vez hechas todas estas comprobaciones, se puede lanzar la instalación de PackStack:\npackstack --use-epel=y --provision-image-url=/root/cirros-0.3.4-x86_64-disk.img --allinone ","date":1455753600,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1455753600,"objectID":"a0b48708354bb0424581ef1681554b86","permalink":"https://blog.okelet.com/post/2016/02/instalar-openstack-packstack-detras-de-un-proxy/","publishdate":"2016-02-18T00:00:00Z","relpermalink":"/post/2016/02/instalar-openstack-packstack-detras-de-un-proxy/","section":"post","summary":"Trasteando con Openstack, con ganas desde hace tiempo, y después de la Mini-Conf del grupo MAD for OpenStack, me animé a probarlo usando PackStack, que te lo configura todo en una única máquina (no tengo claro si se puede considerar una instalación productiva o sólo para pruebas), aunque luego puedes ir añadiendo nodos adicionales. Dado que no tengo acceso a ningún host físico, instalé un RH 7.2 (también vale Fedora o CentOS) en una máquina virtual de VMware (el rendimiento dependerá en gran medida si se tiene habilitado o no la  nested virtualization). Empecé con una máquina con 2 procesadores y 2 GB de RAM, pero enseguida me di cuenta que se quedaba muy corta, incluso sin ninguna instancia arrancada. La versión final tiene 8 procesadores y 8 GB de RAM.\n","tags":null,"title":"Instalar OpenStack PackStack detrás de un proxy","type":"post"},{"authors":null,"categories":null,"content":"Nota: No soy un experto en licencias o suscripciones, así que todo lo que diga en este post, no se debe tomar al pie de la letra. Si algún concepto está mal, comentádmelo y lo corrijo.\nEn un anterior cliente (de cuyo nombre no quiero acordarme), supongo que al igual que en muchos otros que os habréis encontrado, tienen la mala costumbre de instalar software sin licencia o suscripción. En este caso, voy a hablar de Red Hat, y su distribución Linux (Red Hat Enterprise Linux o RHEL). Aunque GNU/Linux siempre se ha caracterizado por sus licencias abiertas, quien modifique dicho software está obligado a publicar dicho fuente modificado (realmente depende de la licencia de cada pieza software que compone la distribución, pero aunque no se deba en general, en este post generalizaremos\u0026hellip;). Éste es, en parte, el negocio de Red Hat. Ellos hace una recopilación de software, le hacen una serie de modificacionesy mejoras si procede, publican ese código fuente ( SRPMs), y finalmente generar unos binarios que los meten en un CD, además de dar actualizaciones y soporte de ese software. ¿Y qué es lo que pasa? Pues esos CDs \u0026ldquo;no te los puedes bajar gratis\u0026rdquo; (dependiendo de la licencia se puede permitir cobrar por el trabajo realizado, o incluso no liberar las modificaciones hechas). Esos CDs sólo los puedes conseguir si tienes una suscripción con Red Hat (previo pago), o bien si te has registrado para una evaluación. Esta demo incluye lo siguiente:\n Actualizaciones durante 30 días NO se incluye soporte técnico  De acuerdo con el acuerdo de licencia de Red Hat Enterprise Linux:\n Beneficios de las Suscripciones de Software: Por cada Suscripción de Software que compra, Red Hat le proporciona uno o más de los siguientes beneficios:\n   Acceso al Software: Acceso al Software. Mantenimiento del Software: Acceso a actualizaciones, nuevas versiones, correcciones, advertencias de seguridad y corrección de defectos para el Software, cuando y en caso de que estuvieran disponibles. Asistencia: Acceso a la asistencia de Red Hat para cuestiones relacionadas con el Software usado para fines de desarrollo y/o fines de producción (cada uno de los cuales se define a continuación). Open Source Assurance: Las compras en virtud de este Apéndice de las Suscripciones de Software pueden darle derecho a participar en el Programa de Open Source Assurance de Red Hat conforme a un contrato por separado, que se puede consultar (en inglés) en www.redhat.com/legal/open_source_assurance_agreement.html.   Vale, me he registrado para una evaluación y me lo he bajado (o bien lo he conseguido por otros medios, ejem), me lo he instalado, y se han pasado los 30 días de evaluación, ¿ahora qué? Pues en principio podrías seguir usándolo. Y entonces, ¿por qué pagar una suscripción? Pues básicamente porque no tendrás acceso a las actualizaciones (algo muy peligroso), pero allá cada uno, y a mayores no tendrías el soporte que te daría una suscripción.\n¿Y por qué no usar suscripciones de evaluación indefinidamente (siempre en caso de que sólo queramos actualizaciones y no soporte)? Básicamente porque es una chapuza y no puedes. Tras solicitar una suscripción de prueba, no puedes volver a solicitar otra del mismo producto hasta 90 días después, con la misma cuenta. Podrías usar cuentas de correo falsas para crear nuevas cuentas en Red Hat, y prolongar la agonía indefinidamente\u0026hellip;. Pero en resumen, chapuzas y ñapas, y aparte puede que te \u0026ldquo;pillen\u0026rdquo;.\nY entonces, ¿por qué no usa todo el mundo CentOS, si es igual que Red Hat? Bueno, si eres administrador de sistemas, y estos no son muy críticos, pues puedes pasar. Pero si eres un pinchaiconos, y no te quieres calentar mucho la cabeza, o eres una gran organización, y necesitas que haya una empresa por detrás que te resuelva los problemas o te aconseje en el despliegue de los sistemas, pues deberías plantearte la suscripción. Si bien es cierto que las suscripciones no son baratas para una pequeña o mediana empresa, en ciertos casos pueden salir rentables.\n¿Y cuándo sí que es imprescindible una suscripción? Por ejemplo, si queremos instalar el servidor de base de datos Oracle, éste sólo está soportado oficialmente en Red Hat (y no en CentOS), y además, en muchos casos requieren unas versiones de paquetes que sólo están disponibles en los repositorios de actualizaciones. ¿Y no es posible instalar una versión mayor o menor? Pues sí que es posible, pero Oracle no daría soporte si no se cumplen sus requerimientos. ¿Y si instalo el paquete de actualizado pero de CentOS? Pues eso se ve fácil con un rpm -q, y se vería que no es la versión compilada para Red Hat, sino la de CentOS. ¿Y no podría compilar yo mismo el SRPM? Podrías, pero volvemos a lo de antes: chapuza, ñapa.\nY volviendo a este cliente que os comentaba, la razón que alegaba para instalar Red Hat sin suscripciones es \u0026ldquo;por si algún día tenemos un problema, compramos una suscripción para esa máquina, y listo\u0026rdquo;. Qué queréis que os diga, me reservo la opinión. Así no. Así no se avanza con el software libre. Y \u0026ldquo;promover\u0026rdquo; el software libre no es simplemente usarlo, que también. Si no se contribuye, se colabora, se hacen donaciones, etc. al final esto no creo que salga bien. Por ejemplo, en las administraciones públicas, pongamos que sustituyen Microsoft Office (cuyo coste en licencias fuera, por ejemplo, de 600.000 euros) y lo cambian por LibreOffice. Qué les costaría, ya que se están ahorrando ese dineral, donar, yo qué sé, un 10% a la Document Foundation, que se encarga del desarrollo; es algo nimio para la administración, pero un gran aporte para la fundación. Si todas las administraciones públicas hicieran esto, no habría, seguramente, tantas quejas sobre la calidad del software (no por LibreOffice, sino por muchas otras aplicaciones que, en mi opinión, se incluyen en muchas distribuciones y que no son alternativas válidas para otras aplicaciones ya consolidadas). Por ejemplo, Linux Mint (para mi la mejor distribución Linux actualmente, en cualquiera de sus entornos), tiene una lista de donantes (la mayoría son particulares), y casi todas son donaciones pequeñas. Pero muchas pequeñas donaciones hacen que se avance.\n  What access and functionality do I lose when the support contract expires for a Red Hat Enterprise Linux product?  RHEL 6 and Trial Subscription: Keeping It Alive  Why can\u0026rsquo;t I find a free download of Red Hat? ","date":1411469657,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1411469657,"objectID":"6e21278275c2a927176179bc1dc6ab72","permalink":"https://blog.okelet.com/post/2014/09/red-hat-licencias-y-suscripciones-y-una-pequena-reflexion-sobre-el-software-libre/","publishdate":"2014-09-23T10:54:17Z","relpermalink":"/post/2014/09/red-hat-licencias-y-suscripciones-y-una-pequena-reflexion-sobre-el-software-libre/","section":"post","summary":"Nota: No soy un experto en licencias o suscripciones, así que todo lo que diga en este post, no se debe tomar al pie de la letra. Si algún concepto está mal, comentádmelo y lo corrijo.\nEn un anterior cliente (de cuyo nombre no quiero acordarme), supongo que al igual que en muchos otros que os habréis encontrado, tienen la mala costumbre de instalar software sin licencia o suscripción. En este caso, voy a hablar de Red Hat, y su distribución Linux (Red Hat Enterprise Linux o RHEL). Aunque GNU/Linux siempre se ha caracterizado por sus licencias abiertas, quien modifique dicho software está obligado a publicar dicho fuente modificado (realmente depende de la licencia de cada pieza software que compone la distribución, pero aunque no se deba en general, en este post generalizaremos\u0026hellip;). Éste es, en parte, el negocio de Red Hat. Ellos hace una recopilación de software, le hacen una serie de modificacionesy mejoras si procede, publican ese código fuente ( SRPMs), y finalmente generar unos binarios que los meten en un CD, además de dar actualizaciones y soporte de ese software. ¿Y qué es lo que pasa? Pues esos CDs \u0026ldquo;no te los puedes bajar gratis\u0026rdquo; (dependiendo de la licencia se puede permitir cobrar por el trabajo realizado, o incluso no liberar las modificaciones hechas). Esos CDs sólo los puedes conseguir si tienes una suscripción con Red Hat (previo pago), o bien si te has registrado para una evaluación. Esta demo incluye lo siguiente:\n Actualizaciones durante 30 días NO se incluye soporte técnico ","tags":["redhat","licencias"],"title":"Red Hat, licencias y suscripciones (y una pequeña reflexión sobre el software libre)","type":"post"},{"authors":null,"categories":null,"content":" NXLOG es un sustituto revitalizado para Syslog. Puede recoger los mensajes tanto desde Windows como de Linux, aplicar reglas, y luego enviarlo a distintos sitios (archivos, bases de datos, servicios web, etc.). El caso es que necesitaba instalar este paquete en un CentOS 5 para enviar los LOGs a un servicio web de indexación, pero no había paquetes precompilados para esta versión.\nTras leer la documentación, indicaban que lo único que hay que hacer es bajarse el código fuente y ejecutar el comando ./make_rpm.sh. El caso es que esto tampoco funcionaba, pero después de dar 20000 vueltas, y de pura casulalidad, vi que había 2 ficheros SPEC: uno llamado nxlog.spec y otro llamado nxlog.spec.RHEL5. Mirando el código del script make_rpm.sh he visto que si no se especifica ningún fichero mediante entorno de variable, automáticamente coge el nxlog.spec, así que lo único que hay que hacer es indicarle mediante una variable de entorno el otro fichero SPEC. Fácil y sencillo (después de darle muchas vueltas)\u0026hellip;\nAquí el copy-paste:\nNXLOG_VERSION=2.8.1248 yum install rpm-build apr-devel pcre-devel openssl-devel libdbi-devel libcap-devel expat-devel libtool wget http://sourceforge.net/projects/nxlog-ce/files/nxlog-ce-${NXLOG_VERSION}.tar.gz tar zxvf nxlog-ce-${NXLOG_VERSION}.tar.gz cd nxlog-ce-${NXLOG_VERSION}/packaging/redhat SPEC_FILE=nxlog.spec.RHEL5 ./make_rpm.sh rpm -Uvh rpmbuild/RPMS/x86_64/nxlog-ce-${NXLOG_VERSION}-1.x86_64.rpm ","date":1410791066,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1410791066,"objectID":"3e21d7f39550a37cbb48bc4a64ec4ba8","permalink":"https://blog.okelet.com/post/2014/09/compilar-nxlog-en-red-hatcentos-5/","publishdate":"2014-09-15T14:24:26Z","relpermalink":"/post/2014/09/compilar-nxlog-en-red-hatcentos-5/","section":"post","summary":" NXLOG es un sustituto revitalizado para Syslog. Puede recoger los mensajes tanto desde Windows como de Linux, aplicar reglas, y luego enviarlo a distintos sitios (archivos, bases de datos, servicios web, etc.). El caso es que necesitaba instalar este paquete en un CentOS 5 para enviar los LOGs a un servicio web de indexación, pero no había paquetes precompilados para esta versión.\n","tags":null,"title":"Compilar NXLOG en Red Hat/CentOS 5","type":"post"},{"authors":null,"categories":null,"content":"De la Wikipedia:\n Kernel-based Virtual Machine o KVM, (en español, Máquina virtual basada en el núcleo) es una solución para implementar virtualización completa con Linux. Está formada por un módulo del núcleo (con el nombre kvm.ko) y herramientas en el espacio de usuario, siendo en su totalidad software libre. El componente KVM para el núcleo está incluido en Linux desde la versión 2.6.20.\n  KVM permite ejecutar máquinas virtuales utilizando imágenes de disco que contienen sistemas operativos sin modificar. Cada máquina virtual tiene su propio hardware virtualizado: una tarjeta de red, discos duros, tarjeta gráfica, etc.\n En primer lugar, debemos comprobar si nuestro equipo es compatible con KVM:\negrep --color '(svm|vmx)' /proc/cpuinfo  Si la salida anterior muestra algo, podremos seguir adelante. Si no muestra nada, también podremos seguir, pero no se aprovecharán las capacidades de virtualización del equipo (se hará un fallback a emulación en lugar de virtualización).\nInstalación en Debian/Ubuntu Para Debian/Ubuntu, deberemos instalar los siguientes paquetes:\nsudo apt-get install cpu-checker qemu-kvm libvirt-bin bridge-utils virt-manager virt-viewer libguestfs-tools  También tendremos que añadir nuestro usuario al grupo libvirtd para poder gestionar máquinas virtuales en el sistema con nuestro propio usuario (sin ser root):\nsudo adduser ${USER} libvirtd  Por último, deberemos reiniciar la sesión para que se recarguen nuestros permisos de usuario.\nInstalación en Red Hat/CentOS Para Red Hat/CentOS, deberemos instalar los siguientes paquetes:\nsudo yum install kvm libvirt virt-viewer virt-manager virt-sysprep  Para poder gestionar máquinas virtuales sin necesidad de ser root, deberemos crear un grupo, agregar nuestro usuario a ese grupo, y configurar ese grupo en KVM para permitirle la gestión (básicamente, estamos simulando el comportamiento que Ubuntu ya hace por sí solo, referencia 1 y referencia 2):\nsudo groupadd libvirtd sudo usermod -a -G libvirtd ${USER} sudo sed -r -i -e 's/^#?unix_sock_group = .*/unix_sock_group = \u0026quot;libvirtd\u0026quot;/' \\ -e 's/^#?unix_sock_rw_perms = .*/unix_sock_rw_perms = \u0026quot;0770\u0026quot;/' \\ -e 's/^#?auth_unix_rw = .*/auth_unix_rw = \u0026quot;none\u0026quot;/' \\ /etc/libvirt/libvirtd.conf sudo service libvirtd restart  Por último, deberemos reiniciar la sesión para que se recarguen nuestros permisos de usuario.\nHerramientas principales de gestión Con KVM disponemos de varias herramientas para gestionar tanto el sistema como las propias máquinas virtuales:\n virsh: nos permite gestionar el sistema y las máquinas virtuales a un nivel medio-bajo. virt-install: nos permite crear máquinas virtuales de una forma sencilla.  Tipos de conexión En la instalación por defecto, tenemos dos tipos de conexión:\n qemu:///system: nos conectamos al servicio de virtualización del sistema. Las máquinas creadas aquí se pueden configurar para que arranquen automáticamente cuando se inicie el host. quemu:///session: nos conectamos a nuestra propia sesión. Estas máquinas sólo las podrá ver y gestionar el propio usuario, y además, los archivos de imagen (discos duros, etc.), deberán estar en una ubicación donde el usuario pueda leer y escribir (en la ruta por efecto /var/lib/libvirt/images sólo puede escribir cuando nos conectamos a la URL de sistema).  Según las pruebas que he hecho, los comandos virsh y virt-instal (explicados en la siguiente sección) se comportan de manera distinta a la hora de conectarse. virsh por defecto se conecta a quemu:///system, mientras que virt-install se conecta a quemu:///session. Por esto, en los siguientes ejemplos, se especifica siempre como URL de conexión quemu:///system, ya que las imágenes de disco se van a crear en /var/lib/libvirt/images. Si no especificásemos URL de conexión, o pusiéramos la de sesión del usuario, deberíamos establecer una ruta de imagen de disco donde el propio usuario pueda escribir, como ${HOME}.\nInstalación de virt-manager actualizado Uso Ubuntu 13.10 y la versión en los repositorios es la 0.9.5. La última versión de virt-manager es la 1.0.1, pero no está en los repositorios para esta versión de Ubuntu (aunque sí a partir de la 14.04); esta última versión tiene bastantes mejoras, entre ellas, la gestión de snapshots. Para instalar la nueva versión no hay más que descargarse el fuente (está escrita en Python); no hay que compilar ni instalar como root (se pueden tener las 2 versiones de virt-manager, la de los repositorios y la instalada a mano, pero hay que tener cuidado con cuál ejecutamos para no volverse uno loco).\nEn primer lugar, tenemos que descargar una serie de dependencias adicionales que necesitamos (referencias uno y dos):\nsudo apt-get install gir1.2-spice-client-gtk-3.0 python-gtk-vnc libglib2.0-bin python-ipaddr libvirt-glib-1.0-dev gir1.2-gtk-vnc-2.0  En principio esto también valdría para Red Hat/CentOS, pero no he encontrado el paquete necesario para la dependencia gi.repository en CentOS 6, y no he podido hacerlo funcionar.\nyum install python-argparse ...  Después de instalar las dependencias, nos bajamos el paquete fuente, lo descomprimimos y lo ejecutamos:\nwget http://virt-manager.org/download/sources/virt-manager/virt-manager-1.0.1.tar.gz -O - | tar -xz cd virt-manager-1.0.1 ./virt-manager  Comandos útiles Mostrar la lista de máquinas en ejecución en el sistema:\nvirsh -c qemu:///system list  Mostrar todas las máquinas configuradas en el sistema:\nvirsh -c qemu:///system list --all  En los comandos anteriores, podemos sustituir qemu:///system por quemu:///session para ver las máquinas asociadas a nuestro usuario (ver apartado anterior).\nMostrar lista de tipos de sistemas operativos; esto es necesario saberlo para cuando vayamos a instalar una máquina con virt-install, ya que deberemos especificar el tipo en el momento de la creación:\nvirt-install --os-variant list  Parar a lo bruto una máquina:\nvirsh destroy nombre_maquina  Eliminar una máquina y todos sus ficheros asociados (snapshots, ficheros de disco, etc.):\nvirsh undefine --managed-save --snapshots-metadata --remove-all-storage nombre_maquina  Creación rápida de máquinas comunes CentOS 5 32 bits:\nvirt-install --connect qemu:///system -n centos5x32 -r 512 --vcpus=1 --os-variant=rhel5.4 \\ --graphics spice --disk path=/var/lib/libvirt/images/centos5x32.qcow2,format=qcow2,size=8 \\ -l http://sunsite.rediris.es/mirror/CentOS/5/os/i386 \\ -x \u0026quot;lang=es_ES keyboard=es\u0026quot;  CentOS 5 64 bits:\nvirt-install --connect qemu:///system -n centos5x64 -r 512 --vcpus=1 --os-variant=rhel5.4 \\ --graphics spice --disk path=/var/lib/libvirt/images/centos5x64.qcow2,format=qcow2,size=8 \\ -l http://sunsite.rediris.es/mirror/CentOS/5/os/x86_64 \\ -x \u0026quot;lang=es_ES keyboard=es\u0026quot;  CentOS 6 32 bits:\nvirt-install --connect qemu:///system -n centos6x32 -r 1024 --vcpus=1 --os-variant=rhel6 \\ --graphics spice --disk path=/var/lib/libvirt/images/centos6x32.qcow2,format=qcow2,size=8 \\ -l http://sunsite.rediris.es/mirror/CentOS/6/os/i386 \\ -x \u0026quot;lang=es_ES keyboard=es\u0026quot;  CentOS 6 64 bits:\nvirt-install --connect qemu:///system -n centos6x64 -r 1024 --vcpus=1 --os-variant=rhel6 \\ --graphics spice --disk path=/var/lib/libvirt/images/centos6x64.qcow2,format=qcow2,size=8 \\ -l http://sunsite.rediris.es/mirror/CentOS/6/os/x86_64 \\ -x \u0026quot;lang=es_ES keyboard=es\u0026quot;  CentOS 7 64 bits ( no existe versión de 32 bits):\nvirt-install --connect qemu:///system -n centos7x64 -r 1024 --vcpus=1 --os-variant=rhel7 \\ --graphics spice --disk path=/var/lib/libvirt/images/centos7x64.qcow2,format=qcow2,size=8 \\ -l http://sunsite.rediris.es/mirror/CentOS/7/os/x86_64 \\ -x \u0026quot;lang=es_ES keyboard=es\u0026quot;  Debian 7 32 bits:\nvirt-install --connect qemu:///system -n debian7x32 -r 512 --vcpus 1 --os-variant debianwheezy \\ --graphics spice --disk path=/var/lib/libvirt/images/debian7x32.qcow2,format=qcow2,size=8 \\ -l http://ftp.debian.org/debian/dists/wheezy/main/installer-i386/ \\ -x \u0026quot;language=es country=ES debian-installer/locale=es_ES.UTF-8 keyboard-configuration/xkb-keymap=es\\ time/zone=Europe/Madrid passwd/make-user=false\u0026quot;  Debian 7 64 bits:\nvirt-install --connect qemu:///system -n debian7x64 -r 512 --vcpus 1 --os-variant debianwheezy \\ --graphics spice --disk path=/var/lib/libvirt/images/debian7x64.qcow2,format=qcow2,size=8 \\ -l http://ftp.debian.org/debian/dists/wheezy/main/installer-amd64/ \\ -x \u0026quot;language=es country=ES debian-installer/locale=es_ES.UTF-8 keyboard-configuration/xkb-keymap=es \\ time/zone=Europe/Madrid passwd/make-user=false\u0026quot;  Los comandos anteriores tienen el parámetro -x (--extra-args). Estos parámetros se pasan automáticamente al kernel de arranque de instalación del sistema operativo. Con ellos, podemos configurar automáticamente ciertos parámetros que se nos pide durante la instalación (los más usados en los ejemplos anteriores sirven para configurar el idioma, la localización, la distribución del teclado, la zona horaria, o incluso si crear o no un usuario regular en el sistema). También es posible pasar una ruta a un fichero KickStart (Red Hat/CentOS) o Preseed (Debian/Ubuntu) para automatizar completamente la instalación. Más información:\n Red Hat/CentOS: parámetros de arranque uno y dos, Kickstart Debian/Ubuntu: parámetros de arranque, Preseed  Para especificar un proxy de instalación en los casos anteriores, se deben especificar las siguientes opciones:\n Para Debian/Ubuntu: mirror/http/proxy=http://[usuario:contraseña@]proxy.dominio.com:3128/ Para CentOS/Red Hat: proxy=http://[usuario:contraseña@]proxy.dominio.com:3128/  La opción --graphics spice especificada en los comandos anteriores permite una mejor calidad y mayor rendimiento de los gráficos en la máquina virtual, usando el driver qxl, así como una mejor integración con el host a través del protocolo Spice, permitiendo el cambio de resolución de la máquina virtual según redimensionemos el visor, redirección del sonido, copiar y pegar, etc. En caso de que no se especifique esta opción se usaría una comunicación mediante VNC y un driver Cirrus. Para que el protocolo Spice funcion correctamente en la máquina virtual, deberemos asegurarnos que está instalado el driver gráfico adecuado y el agente de Spice, según lo indicado en el siguiente apartado.\nCambiar Cirrus/VNC por QXL/Spice Como he comentando antes, el protocolo Spice ofrece un rendimiento mayor y mejor integración con el huésped. Si tenemos alguna máquina virtual creada con las opciones por defecto, podemos actualizarla cambiando las opciones adecuadas. Para ello, con la máquina virtual parada, editaremos su configuración XML y mofificaremos los bloques especificados a continuación:\nvirsh edit nombre_maquina  \u0026lt;channel type='spicevmc'\u0026gt; \u0026lt;target type='virtio' name='com.redhat.spice.0'/\u0026gt; \u0026lt;address type='virtio-serial' controller='0' bus='0' port='1'/\u0026gt; \u0026lt;/channel\u0026gt; \u0026lt;graphics type='spice' autoport='yes'/\u0026gt; \u0026lt;video\u0026gt; \u0026lt;model type='qxl' ram='65536' vram='65536' heads='1'/\u0026gt; \u0026lt;address type='pci' domain='0x0000' bus='0x00' slot='0x02' function='0x0'/\u0026gt; \u0026lt;/video\u0026gt;  Tras esto, ya podemos arrancar la máquina virtual y debemos asegurarnos de tener instalado tanto el driver gráfico correspondiente, como el agente de Spice. Para ello, ejecutaremos los siguientes comandos en distribuciones Debian/Ubuntu:\nsudo apt-get install xserver-xorg-video-qxl spice-vdagent sudo update-rc.d spice-vdagent defaults sudo service spice-vdagent start  Estos otros en distribuciones Red Hat/CentOS con SysV (versiones 6 y anteriores):\nsudo yum install xorg-x11-drv-qxl spice-vdagent sudo chkconfig spice-vdagentd on sudo service spice-vdagentd start  Y estos otros en distribuciones Red Hat/CentOS con Systemd (versiones 7 y posteriores):\nsudo yum install xorg-x11-drv-qxl spice-vdagent sudo systemctl enable spice-vdagentd sudo systemctl start spice-vdagentd  Para finalizar, deberemos reiniciar la máquina virtual para que se apliquen los cambios.\nIntercambiar entre KVM y VirtualBox Si se tiene instalado VirtualBox, KVM no se ejecutará con todas las características de virtualización completas, sino que delegará en QEMU (que es mucho más lento), o bien VirtualBox no se ejecutará diciendo que no se han podido cargar sus módulos ( dependiendo del orden de carga de los módulos de KVM o VirtualBox, será uno u otro el que no funcione). Para solventar esto, o bien debemos desinstalar uno de los dos sistemas, o bien debemos desactivar los módulos del otro cuando vayamos a ejecutar un sistema de virtualización.\nPara usar KVM:\nsudo /etc/init.d/vboxdrv stop sudo modprobe kvm sudo modprobe kvm_intel  Para usar VirtualBox:\nsudo modprobe -r kvm_intel sudo modprobe -r kvm sudo /etc/init.d/vboxdrv start  En mi caso, que tengo en el trabajo un Dell OptiPlex 755, hay que tocar algunas cosas en la BIOS para que funcione correctamente KVM, ya que cuando intentaba cargar el módulo kvm_intel me daba un error de Operation not supported. En esta pregunta de serverfault, que a su vez hace referencia a ésta, indican las opciones de la BIOS que se deben poner para que funcione; en resumen:\n Security: Execute Disable should be On Performance: Virtualization should be On Performance: VT for Direct I/O Access should be On Performance: Trusted Execution should be Off  Snapshots Para poder tomar snapshots, el formato de los discos debe ser alguno que sea compatible; si al crear la máquina, no se especifica uno, se crearán con el formato raw, que no los permite; por eso, en todos los comandos anteriores se usa el formato qcow2.\nMostrar los snapshots de una máquina:\nvirsh snapshot-list nombre_maquina  Tomar un snapshot de una máquina:\nvirsh snapshot-create-as nombre_maquina \u0026quot;Nombre del snapshot (opcional)\u0026quot; \u0026quot;Descripción del snapshot (opcional)\u0026quot;  Revertir a un snapshot anterior:\nvirsh snapshot-revert nombre_maquina [nombre_snapshot|--current]  Eliminar un snapshot:\nvirsh snapshot-delete nombre_maquina [nombre_snapshot|--current] [{--children | --children-only}]  Convertir imágenes de disco a QCOW2 En caso de que tengamos una máquina virtual con un disco en formato raw, no podremos utilizar la funcionalidad de snapshots, como hemos comentado antes. Para solucionar esto, deberemos convertir el fichero de imagen de la máquina a formato qcow2, y luego editar la configuración de la máquina virtual para decirle que hemos cambiado el formato del disco.\nPara convertir el formato (se debe hacer con la máquina apagada, y con sudo ya que necesita acceder directamente al disco para leerlo y luego poder crear el nuevo):\nsudo qemu-img convert -f raw -O qcow2 /var/lib/libvirt/images/centos7x64.{img,qcow2}  Tras esto, debemos reconfigurar la máquina virtual para indicar el nuevo nombre del fichero y formato del disco (al igual que antes, con la máquina apagada):\nvirsh edit centos7x64  \u0026lt;disk type='file' device='disk'\u0026gt; \u0026lt;driver name='qemu' type='qcow2'/\u0026gt; \u0026lt;source file='/var/lib/libvirt/images/centos7x64.qcow2'/\u0026gt; \u0026lt;target dev='vda' bus='virtio'/\u0026gt; \u0026lt;address type='pci' domain='0x0000' bus='0x00' slot='0x04' function='0x0'/\u0026gt; \u0026lt;/disk\u0026gt;  Clonar máquinas virtuales A la hora de clonar máquinas virtuales debemos tener en cuenta varias cosas:\n Se debe duplicar el disco Se debe generar una nueva dirección MAC para cada una de las tarjetas de red A nivel de sistema operativo:  Cambiar la dirección MAC con la nueva en los archivos de configuración (/etc/sysconfig/network-scripts/ifcfg-eth* en Red Hat/CentOS) Se deben eliminar y regerenerar las claves SSH antiguas Se deberían eliminar los usuarios del sistema original   Y cualquier cosa más que se nos ocurra  Para realizar todas estas tareas, disponemos principalmente de 2 herramientas:\n virt-clone: realiza el clonado en sí de la máquina, copiando el disco, y cambiando las direcciones MAC de las tarjetas (a nivel de KVM sólo, no a nivel del sistema operativo virtual). virt-sysprep: permite realizar modificaciones en el sistema operativo para configurarlo correctamente con las nuevas especificaciones (MAC, SSH, etc.).  Desde la aplicación virt-manager es bastante sencillo, pues se realiza en apenas 2 clicks por la interfaz gráfica. Para hacerlo por comandos, realizaremos los siguientes pasos. En primer lugar, clonaremos la máquina en sí (si no especificamos manualmente un disco de destino con la opción --file, se nos creará uno automáticamente con el nombre de a nueva máquina; si no especificamos tampoco una MAC manualmente con el parámetro --mac, se generará una aleatoria automáticamente):\nvirt-clone --connect qemu:///system --original centos6x32 --auto-clone --name centos6x32-clone  Tras esto, ejecuataremos (virt-sysprep se tiene que ejecutar con sudo o dar permisos de lectura y escritura al usuario actual sobre el archivo de imagen de la máquina virtual, ya que tiene que realizar modificaciones directamente sobre él):\nsudo virt-sysprep --connect qemu:///system --domain centos6x32-clone  El comando anterior lanzará una serie de modificaciónes estándar; estas modificaciones se pueden personalizar con los parámetros --enable y --operations; es posible ver la lista de operaciones posibles con el parámetro --list-operations, y ver lo que se haría sobre la máquina sin realmente hacerlo con el parámetro --dry-run.\nNOTA: La versión de Ubuntu que utilizo es la 13.10, que tiene una versión bastante antigua del comando virt-sysprep, y no reconoce varias de las opciones anteriores, y tiene este bug; para solventarlo, lo que hago es pasarle manualmente la lista de operaciones a realizar:\nsudo virt-sysprep --connect qemu:///system -d centos6x32-clone --enable bash-history,logfiles,hostname,machine-id,net-hwaddr,ssh-hostkeys,ssh-userdir  Hay una herramienta adicional (virt-customize) que permite realizar modificaciones sobre el sistema operativo (al estilo de Ansible, Puppet, Salt, Chef, etc. pero más básico), pudiendo establecer la contraseña de root y de usuarios, instalar paquetes, actualizar el sistema, establecer el nombre de host, etc. Lamentablemente, esta aplicación sólo está disponible a partir de la versión 1.26 de libguestfs, que es bastante posterior a la que hay en Ubuntu. Simplemente, a modo de referencia, el comando funcionaría de la siguiente forma:\nsudo virt-customize --connect qemu:///system -d centos6x32-clone --hostname nuevonombre.pruebas.test  Referencias:\n  man virt-customize  man virt-sysprep  Richard WM Jones: virt-sysprep ","date":1407841968,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1407841968,"objectID":"19b38a02a22e0e21345ede15a1253e14","permalink":"https://blog.okelet.com/post/2014/08/guia-rapida-de-kvm/","publishdate":"2014-08-12T13:12:48+02:00","relpermalink":"/post/2014/08/guia-rapida-de-kvm/","section":"post","summary":"De la Wikipedia:\n Kernel-based Virtual Machine o KVM, (en español, Máquina virtual basada en el núcleo) es una solución para implementar virtualización completa con Linux. Está formada por un módulo del núcleo (con el nombre kvm.ko) y herramientas en el espacio de usuario, siendo en su totalidad software libre. El componente KVM para el núcleo está incluido en Linux desde la versión 2.6.20.\n  KVM permite ejecutar máquinas virtuales utilizando imágenes de disco que contienen sistemas operativos sin modificar. Cada máquina virtual tiene su propio hardware virtualizado: una tarjeta de red, discos duros, tarjeta gráfica, etc.\n En primer lugar, debemos comprobar si nuestro equipo es compatible con KVM:\negrep --color '(svm|vmx)' /proc/cpuinfo  Si la salida anterior muestra algo, podremos seguir adelante. Si no muestra nada, también podremos seguir, pero no se aprovecharán las capacidades de virtualización del equipo (se hará un fallback a emulación en lugar de virtualización).\n","tags":null,"title":"Guía rápida de KVM","type":"post"},{"authors":null,"categories":null,"content":"Una de las cosas que más echo en falta en VirtualBox con respecto a cuando trabajaba con VMware Workstation o Player, al trabajar una máquina local para hacer pruebas, es que estas últimas te creaban varios tipos de redes por defecto que VirtualBox no hace. La más útil para mi, sobre todo cuando estás en un cliente en el que es difícil solicitar IPs o cuando quieres crear una red interna de pruebas, es crear una red privada de la que formen parte tanto las máquinas virtuales como la propia máquina anfitriona, y que tenga salida al exterior mediante NAT.\nEn las últimas versiones de VirtualBox (a partir de la 4.3, en modo experimental) existe el llamado NAT Service, que simula el comportamiento anterior de VMware, pero que no permite la conexión desde la máquina anfitriona (ya que, al contrario que VMware, VirtualBox no crea una interfaz virtual para esta red) hacia las máquinas virtuales o a la inversa. Esto es muy cómodo cuando quieres hacer SSH hacia las máquinas virtuales, ya que no tienes que estar redirigiendo puertos, que es la única forma de hacerlo con VirtualBox en el modo NAT Service (y no digamos si tienes varias máquinas virtuales, el lío de redirección de puertos y parámetros al SSH para conectar a las diferentes máquinas virtuales).\nBuscando una solución alternativa y lo más transparente y sencilla de gestionar, hace tiempo descubrí esta página que lo que hace es crear una interfaz virtual en la máquina anfitrión, configurando el reenvío TCP y un servidor Dnsmasq para servir direcciones por DHCP y la resolución DNS de esa red. De esta forma, si la red de las máquinas virtuales se configura en modo bridge, usando la interfaz creada, todas podrán comunicarse entre sí y con la máquina anfitrión, aparte de tener un servidor DHCP y DNS (por lo que podremos crear asignaciones de direcciones estáticas, entradas DNS para un dominio ficticio interno, etc.). Además, las máquinas virtuales tendrán salida al exterior, ya que la máquina anfitrión realizará NAT del tráfico saliente que se reciba desde esta red. Incluso podemos montar un servidor PXE para arrancar sistemas en red o la instalación automática mediante Kickstart, Clobber o Preseed.\nPara rizar aún más el rizo, decidí simplificar la configuración. La anterior está bien, pero es necesario tener bastantes cosas en cuenta (la interfaz, el paquete bridge-utils, el reenvío TCP, la configuración de Dnsmasq, etc.), y se complica a mayores cuando quieres tener varias redes virtuales separadas y que se comuniquen entre sí. Buscando un poco más, descubrí esta página en la que se combinan todos los pasos anteriores en un único punto. En resumen, lo que se hace es crear una interfaz virtual, y en los precomandos y postcomandos al levantar y apagar la interfaz, se ejecutan todos los pasos necesarios. Para poner en marcha esto, lo primero será instalar Dnsmasq y los paquetes necesarios para crear la interfaz virtual:\napt-get install dnsmasq vde2 bridge-utils update-rc.d dnsmasq disable   Es necesario deshabilitar dnsmasq del arranque ya que la configuración por defecto escucha por todas las interfaces, y al levantar dnsmasq por cada interfaz virtual, da un error diciendo que la dirección ya está en uso.   Para no tener que tocar mucho el archivo /etc/network/interfaces, y poder gestionar más fácilmente las interfaces virtuales que creemos, configuraremos el sistema para que cargue dinámicamente todos los archivos de configuración desde el directorio /etc/network/interfaces.d; para ello, tendremos que añadir, si no existe ya, esta línea:\nauto lo iface lo inet loopback source /etc/network/interfaces.d/*.cfg  Y por supuesto, crear dicho directorio:\nmkdir -p /etc/network/interfaces.d  A continuación, ya podemos definir la interfaz (fichero /etc/network/interfaces.d/vnet0.cfg):\nauto vnet0 iface vnet0 inet static address 192.168.77.253 netmask 255.255.255.0 ############################################################################################################ # Arranque de la interfaz ############################################################################################################ # Crear la interfaz virtual pre-up /usr/bin/vde_switch --tap ${IFACE} --daemon --group vde2-net --sock /var/run/${IFACE}.ctl \\ --mod 775 --mgmtmode 770 --mgmt /var/run/${IFACE}-manage --pidfile /var/run/${IFACE}_vde.pid # Comprobamos si existe un archivo de configuración de Dnsmasq, y si no existe, creamos uno vacío # para que no se queje el proceso de Dnsmasq al levantarlo up test -e /etc/dnsmasq_${IFACE}.conf || touch /etc/dnsmasq_${IFACE}.conf # Levantar el proceso de Dnsmasq, pasando como interfaz a la que asociarse la propia interfaz y el # rango DHCP para asignar direcciones (la dirección de la interfaz definida arriba debe estar en este # rango); se pueden especificar más parámetros añadiéndolos aquí o creando/modificando un archivo # de configuración según la instrucción anterior. up /usr/sbin/dnsmasq --interface=${IFACE} --except-interface=lo --bind-interfaces --user=nobody \\ --dhcp-range=${IFACE},192.168.77.101,192.168.77.199,8h \\ --local=/pruebas.intra/ --domain=pruebas.intra \\ --pid-file=/var/run/${IFACE}_dnsmasq.pid --conf-file=/etc/dnsmasq_${IFACE}.conf # Añadir una regla a iptables para natear el tráfico saliente de esta red post-up iptables -t nat -I POSTROUTING -s 192.168.77.0/24 -j MASQUERADE ############################################################################################################ # Parada de la interfaz ############################################################################################################ # Eliminar el nateo del tráfico saliente asociada a la red pre-down iptables -t nat -D POSTROUTING -s 192.168.77.0/24 -j MASQUERADE # Parar el proceso de Dnsmasq down kill $(cat /var/run/${IFACE}_dnsmasq.pid) \u0026amp;amp;\u0026amp;amp; rm -f /var/run/${IFACE}_dnsmasq.pid # Borrar el archivo de configuración de Dnsmasq si está vacío (para mantener limpio el sistema) down test -s /etc/dnsmasq_${IFACE}.conf || rm -f /etc/dnsmasq_${IFACE}.conf # Eliminar la interfaz virtual post-down kill $(cat /var/run/${IFACE}_vde.pid) || kill -9 $(cat /var/run/${IFACE}_vde.pid)   En el post original de donde saqué esta configuración (el segundo referenciado), la regla de iptables hacía referencia a la interfaz de salida, y no a la red de origen como he puesto yo. Esto lo he tenido que hacer ya que Ubuntu usa NetworkManager, y parece que levanta esta interfaz antes que las demás (por ejemplo, con la que tengamos configurada como principal como eth0 o wlan0), por lo que no es posible la interfaz de salida de la ruta por defecto (y que además esta interfaz puede cambiarse desde el escritorio). Por tanto, lo que he hecho, es que en la regla de iptables, en lugar de hacer NAT a todo lo que salga por la interfaz por defecto tras el enrutado, es hacer NAT a todo lo que venga de la red de la interfaz virtual tras el enrutado.\nEsto tiene un problema, que no creo que sea difícil de solucionar, pero que no lo he hecho, y es que si hay varias interfaces virtuales y queremos comunicar máquinas de distintas redes, siempre se hará NAT, aunque no salgan del propio host anfitrión.\n  El único paso que he dejado fuera es la configuración del reenvío TCP, ya que no está ligado a una interfaz en concreto, sino que va a nivel de sistema.\nnet.ipv4.ip_forward=1  Recargamos la configuración para que se aplique el cambio anterior:\nsysctl -p  Las ventajas de esta configuración sobre la primera es que:\n Se levanta un proceso Dnsmasq distinto para cada interfaz, con un archivo de configuración específico, por lo que se pueden agregar en el fichero datos que no se pasan directamente al programa por parámetros, como asignaciones de IPs estáticas, registros DNS, etc. Se pueden tener varias interfaces virtuales, cada una con su propia configuración DNS, simplemente creando una nueva interfaz copiando y pegando tantas veces el bloque anterior y modificando los datos mínimos (sobre todo la dirección IP, el rango DHCP y las reglas de iptables), o creando un archivo distinto por cada interfaz en el directorio /etc/network/interfaces.d.  Para finalizar, se puede modificar la configuración de Dnsmasq para personalizar las asignaciones DHCP, la resolución DNS, así como hacer que los sistemas arranquen desde la red con PXE; hay configuraciones de ejemplo en esta página.\n","date":1407412199,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1407412199,"objectID":"1bd04d3b472000691ee627c064967ef2","permalink":"https://blog.okelet.com/post/2014/08/red-nat-privada-con-salida-al-exterior-en-virtualbox/","publishdate":"2014-08-07T13:49:59+02:00","relpermalink":"/post/2014/08/red-nat-privada-con-salida-al-exterior-en-virtualbox/","section":"post","summary":"Una de las cosas que más echo en falta en VirtualBox con respecto a cuando trabajaba con VMware Workstation o Player, al trabajar una máquina local para hacer pruebas, es que estas últimas te creaban varios tipos de redes por defecto que VirtualBox no hace. La más útil para mi, sobre todo cuando estás en un cliente en el que es difícil solicitar IPs o cuando quieres crear una red interna de pruebas, es crear una red privada de la que formen parte tanto las máquinas virtuales como la propia máquina anfitriona, y que tenga salida al exterior mediante NAT.\n","tags":null,"title":"Red NAT privada con salida al exterior en VirtualBox","type":"post"},{"authors":null,"categories":null,"content":"La página de IBM developerWorks no para de sorprenderme. Muchas de las veces que busco documentación técnica, cursos, tutoriales, etc. allí están ellos, y con un material gratuito y de muy alta calidad. La última, fue con la instalación de este blog. Tengo un VPS contratado con Ubuntu, que he ido actualizando poco a poco, y que lo tengo bastante pelado. Me decidí por instalar en él WordPress (tras mucho analizar otros sistemas para publicar artículos tipo Dokuwiki, Octopress, Jekyll, Pelican, etc.). Lo primero que me sorprendió es que no soporta PostgreSQL de forma oficial (que sería mi primera opción), por mis reticencias con MySQL, pero más tarde de acordé del fork que se creó hace un tiempo, llamado MariaDB. Leyendo un poco, parece ser que MariaDB es \u0026ldquo;binariamente\u0026rdquo; (si es que eso existe en castellano) compatible con MySQL (es decir, que el protocolo de comunicación, los ficheros de base de datos, etc. son totalmente compatibles, si no iguales).\nBueno, a lo que iba. Ya que con PostgreSQL no se puede (o por lo menos, no está oficialmente soportado), opté por instalar MariaDB. Desde su web tienen un asistente muy sencillo para configurar los repositorios de las distribuciones Linux más comunes (openSUSE, Debian, Ubuntu, Red Hat, CentOS, etc.). Tienen paquetes precompilados para prácticamente todas las versiones y arquitecturas (la única que echo en falta es Red Hat 7, aunque se lo perdono porque acaba de salir hace nada\u0026hellip;).\nUna vez configurados los repositorios, toca la parte de la instalación; sencillísima como siempre:\nsudo apt-get update sudo apt-get install mariadb-server php5-mysql  Lo que más miedo me da de estas instalaciones tan \u0026ldquo;sencillísimas\u0026rdquo; es que muchas veces dejan el servidor o el servicio instalado bastante desprotegido. Durante la instalación, se nos pregunta que si queremos ponerle una contraseña al usuario root de MariaDB/MySQL\u0026hellip;. Pero qué cosas, nos permite dejarlo en blanco. MAL MAL MAL. Como decía, gracias a los tutoriales de developerWorks, descubrí que hay un comando muy sencillo que te \u0026ldquo;quita\u0026rdquo; todas esas inseguridades; a saber:\n Ponerle una contraseña al usuario root de MariaDB/MySQL en condiciones. Eliminar el usuario anonymous Deshabilitar el acceso remoto de root Eliminar la base de datos test Recargar los privilegios  El comando mágico es mysql_secure_installation, aunque parece que no está muy afinado, ya que nada más lanzarlo da un error:\n/usr/bin/mysql_secure_installation: 379: /usr/bin/mysql_secure_installation: find_mysql_client: not found  También da un error al intentar borrar la base de datos test:\nRemove test database and access to it? [Y/n] - Dropping test database... ERROR 1008 (HY000) at line 1: Can't drop database 'test'; database doesn't exist ... Failed! Not critical, keep moving... - Removing privileges on test database... ... Success!  Puedes ver la salida completa del comando en este Gist:\n Una vez hecho esto, ya podemos decir que nuestra instalación está bastante adecentada. Lo que nos quedaría, si usamos un cortafuegos (que deberíamos), sería limitar el acceso. Si la regla por defecto es denegar las conexiones entrantes, no deberíamos tener problema; si no, deberíamos añadir una regla para denegar las conexiones remotas entrantes al puerto 3306. El siguiente listado muestra los comandos necesarios para configurar el cortafuegos de manera rápida con UFW, permitiendo el acceso desde fuera por SSH, HTTP y HTTPS, denegando todo el resto de tráfico entrante, y permitiendo por defecto el tráfico saliente:\nsudo apt-get install ufw sudo ufw enable sudo ufw default deny incoming sudo ufw default allow outgoing sudo ufw allow ssh/tcp sudo ufw allow http/tcp sudo ufw allow https/tcp sudo ufw status  Por último, y como algo particular para WordPress, crearemos una base de datos, un usuario y le daremos permisos al usuario sobre esa base de datos, para lo que ejecutaremos el comando mysql -uroot -p, introduciendo después la contraseña asignada antes al usuario root, y ejecutando los siguientes comandos desde el shell de MariaDB:\nCREATE DATABASE wordpress; CREATE USER 'wpuser'@'localhost' IDENTIFIED BY 'pickApassword'; GRANT ALL PRIVILEGES ON wordpress .* TO 'wpuser'@'localhost'; FLUSH PRIVILEGES; exit  Referencias   IBM developerWorks: Create a secure WordPress blog using SoftLayer ","date":1407412182,"expirydate":-62135596800,"kind":"page","lang":"es","lastmod":1407412182,"objectID":"db05c5b166478520cd7910b27dab59a3","permalink":"https://blog.okelet.com/post/2014/08/instalar-configurar-y-securizar-mariadb/","publishdate":"2014-08-07T13:49:42+02:00","relpermalink":"/post/2014/08/instalar-configurar-y-securizar-mariadb/","section":"post","summary":"La página de IBM developerWorks no para de sorprenderme. Muchas de las veces que busco documentación técnica, cursos, tutoriales, etc. allí están ellos, y con un material gratuito y de muy alta calidad. La última, fue con la instalación de este blog. Tengo un VPS contratado con Ubuntu, que he ido actualizando poco a poco, y que lo tengo bastante pelado. Me decidí por instalar en él WordPress (tras mucho analizar otros sistemas para publicar artículos tipo Dokuwiki, Octopress, Jekyll, Pelican, etc.). Lo primero que me sorprendió es que no soporta PostgreSQL de forma oficial (que sería mi primera opción), por mis reticencias con MySQL, pero más tarde de acordé del fork que se creó hace un tiempo, llamado MariaDB. Leyendo un poco, parece ser que MariaDB es \u0026ldquo;binariamente\u0026rdquo; (si es que eso existe en castellano) compatible con MySQL (es decir, que el protocolo de comunicación, los ficheros de base de datos, etc. son totalmente compatibles, si no iguales).\n","tags":null,"title":"Instalar, configurar y securizar MariaDB","type":"post"}]