<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Cloudwatch | Notas de Cloud y DevOps</title><link>https://blog.okelet.com/tags/cloudwatch/</link><atom:link href="https://blog.okelet.com/tags/cloudwatch/index.xml" rel="self" type="application/rss+xml"/><description>Cloudwatch</description><generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>es-ES</language><copyright>[CC BY-SA](https://creativecommons.org/licenses/by-sa/3.0/) Juan A. S. 2020</copyright><lastBuildDate>Sun, 01 Sep 2019 00:00:00 +0000</lastBuildDate><image><url>img/map[gravatar:%!s(bool=false) shape:circle]</url><title>Cloudwatch</title><link>https://blog.okelet.com/tags/cloudwatch/</link></image><item><title>Monitorizar memoria y errores de funciones Lambda</title><link>https://blog.okelet.com/post/2019/09/monitorizar-memoria-y-errores-de-funciones-lambda/</link><pubDate>Sun, 01 Sep 2019 00:00:00 +0000</pubDate><guid>https://blog.okelet.com/post/2019/09/monitorizar-memoria-y-errores-de-funciones-lambda/</guid><description>&lt;p>A la hora de monitorizar estadísticas sobre la ejecución de nuestras funciones Lambda, Cloudwatch ya nos ofrece algunas &lt;em>builtin&lt;/em> como:&lt;/p>
&lt;ul>
&lt;li>Cantidad de &lt;em>throttles&lt;/em>&lt;/li>
&lt;li>Número de invocaciones&lt;/li>
&lt;li>Número de errores &amp;ldquo;genéricos&amp;rdquo;&lt;/li>
&lt;li>Duración (media y total)&lt;/li>
&lt;/ul>
&lt;p>Pero si queremos ver estadísticas sobre memoria o errores según sean por consumo excesivo de memoria o por timeout, no los tenemos disponibles por defecto.&lt;/p>
&lt;p>Para conseguir información de este tipo de errores, tendremos que recurrir a crear
&lt;a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/MonitoringPolicyExamples.html" target="_blank" rel="noopener">filtros de métricas (&lt;em>metric filters&lt;/em>)&lt;/a> de los LOGs que deja Lambda en Cloudwatch. Por ejemplo, con el siguiente script, recorremos todas los grupos de LOGs de Lambda (aquellos que empiezan por &lt;code>/aws/lambda/&lt;/code>) y creamos unas cuantas métricas en cada uno de ellos, para poder después obtener estadísticas:&lt;/p>
&lt;pre>&lt;code class="language-bash">#!/bin/bash
# Based on https://gist.github.com/sandfox/337129afa5555af6372d4eae536b20f0
prefix=&amp;quot;/aws/lambda/&amp;quot;
for log_group in $(aws logs describe-log-groups --log-group-name-prefix $prefix --query &amp;quot;logGroups[].logGroupName&amp;quot; --output text) ; do
fn_name=${log_group#$prefix};
aws logs put-metric-filter \
--log-group-name &amp;quot;$log_group&amp;quot; \
--filter-name lambda-memory-usage \
--filter-pattern '[ x=&amp;quot;REPORT&amp;quot;, x=&amp;quot;RequestId:&amp;quot;, request_id, x=&amp;quot;Duration:&amp;quot;, duration, x=&amp;quot;ms&amp;quot;, x=&amp;quot;Billed&amp;quot;, x=&amp;quot;Duration:&amp;quot;, billed_duration, x=&amp;quot;ms&amp;quot;, x=&amp;quot;Memory&amp;quot;, x=&amp;quot;Size:&amp;quot;, memory_size, x=&amp;quot;MB&amp;quot;, x=&amp;quot;Max&amp;quot;, x=&amp;quot;Memory&amp;quot;, x=&amp;quot;Used:&amp;quot;, memory_used, x=&amp;quot;MB&amp;quot;]' \
--metric-transformations &amp;quot;metricNamespace=Custom/Lambda,metricName=${fn_name}-MemoryUsed,metricValue=\$memory_used&amp;quot;
aws logs put-metric-filter \
--log-group-name &amp;quot;$log_group&amp;quot; \
--filter-name lambda-memory-size \
--filter-pattern '[ x=&amp;quot;REPORT&amp;quot;, x=&amp;quot;RequestId:&amp;quot;, request_id, x=&amp;quot;Duration:&amp;quot;, duration, x=&amp;quot;ms&amp;quot;, x=&amp;quot;Billed&amp;quot;, x=&amp;quot;Duration:&amp;quot;, billed_duration, x=&amp;quot;ms&amp;quot;, x=&amp;quot;Memory&amp;quot;, x=&amp;quot;Size:&amp;quot;, memory_size, x=&amp;quot;MB&amp;quot;, x=&amp;quot;Max&amp;quot;, x=&amp;quot;Memory&amp;quot;, x=&amp;quot;Used:&amp;quot;, memory_used, x=&amp;quot;MB&amp;quot;]' \
--metric-transformations &amp;quot;metricNamespace=Custom/Lambda,metricName=${fn_name}-MemorySize,metricValue=\$memory_size&amp;quot;
# Errores que se dan cuando la ejecución se pasa del máximo de memoria permitido
aws logs put-metric-filter \
--log-group-name &amp;quot;${log_group}&amp;quot; \
--filter-name lambda-memory-errors \
--filter-pattern 'Process exited before completing request' \
--metric-transformations &amp;quot;metricNamespace=Custom/Lambda,metricName=${fn_name}-MemoryErrors,metricValue=1,defaultValue=0&amp;quot;
# Errores que se dan cuando la ejecución se pasa del máximo de tiempo permitido
aws logs put-metric-filter \
--log-group-name &amp;quot;${log_group}&amp;quot; \
--filter-name lambda-timeout-errors \
--filter-pattern 'Task timed out after' \
--metric-transformations &amp;quot;metricNamespace=Custom/Lambda,metricName=${fn_name}-TimeoutErrors,metricValue=1,defaultValue=0&amp;quot;
done
&lt;/code>&lt;/pre>
&lt;p>Una vez creados, y pasados cierto tiempo para poder obtener datos, en la sección de métricas de Cloudwatch, tendremos una nueva categoría, &lt;code>Custom/Lambda&lt;/code>, donde tendremos el listado de nuevas métricas, por cada función Lambda:&lt;/p>
&lt;p>&lt;img src="cloudwatch_lambda_custom_namespace.png" alt="">&lt;/p>
&lt;p>Podremos seleccionar estas estadísticas para poder visualizar los datos en un gráfico:&lt;/p>
&lt;p>&lt;img src="cloudwatch_lambda_memory_used_graph.png" alt="">&lt;/p>
&lt;p>También podremos consultar estos datos desde la CLI:&lt;/p>
&lt;pre>&lt;code class="language-bash">aws cloudwatch get-metric-statistics --namespace Custom/Lambda --metric-name my_function_name-MemoryUsed --start-time $(date --date &amp;quot;1 day ago&amp;quot; +%s) --end-time $(date +%s) --period 300 --statistics Average
&lt;/code>&lt;/pre>
&lt;pre>&lt;code class="language-json">{
&amp;quot;Label&amp;quot;: &amp;quot;my_function_name-MemoryUsed&amp;quot;,
&amp;quot;Datapoints&amp;quot;: [
{
&amp;quot;Timestamp&amp;quot;: &amp;quot;2019-08-29T04:10:00Z&amp;quot;,
&amp;quot;Average&amp;quot;: 84.32894736842105,
&amp;quot;Unit&amp;quot;: &amp;quot;None&amp;quot;
},
{
&amp;quot;Timestamp&amp;quot;: &amp;quot;2019-08-28T18:10:00Z&amp;quot;,
&amp;quot;Average&amp;quot;: 82.94736842105263,
&amp;quot;Unit&amp;quot;: &amp;quot;None&amp;quot;
},
{
&amp;quot;Timestamp&amp;quot;: &amp;quot;2019-08-29T08:10:00Z&amp;quot;,
&amp;quot;Average&amp;quot;: 83.72368421052632,
&amp;quot;Unit&amp;quot;: &amp;quot;None&amp;quot;
},
{
&amp;quot;Timestamp&amp;quot;: &amp;quot;2019-08-28T22:10:00Z&amp;quot;,
&amp;quot;Average&amp;quot;: 84.63157894736842,
&amp;quot;Unit&amp;quot;: &amp;quot;None&amp;quot;
},
{
&amp;quot;Timestamp&amp;quot;: &amp;quot;2019-08-29T12:10:00Z&amp;quot;,
&amp;quot;Average&amp;quot;: 83.59210526315789,
&amp;quot;Unit&amp;quot;: &amp;quot;None&amp;quot;
},
{
&amp;quot;Timestamp&amp;quot;: &amp;quot;2019-08-29T02:10:00Z&amp;quot;,
&amp;quot;Average&amp;quot;: 83.17105263157895,
&amp;quot;Unit&amp;quot;: &amp;quot;None&amp;quot;
},
{
&amp;quot;Timestamp&amp;quot;: &amp;quot;2019-08-28T16:10:00Z&amp;quot;,
&amp;quot;Average&amp;quot;: 84.35526315789474,
&amp;quot;Unit&amp;quot;: &amp;quot;None&amp;quot;
},
{
&amp;quot;Timestamp&amp;quot;: &amp;quot;2019-08-29T06:10:00Z&amp;quot;,
&amp;quot;Average&amp;quot;: 83.85526315789474,
&amp;quot;Unit&amp;quot;: &amp;quot;None&amp;quot;
},
{
&amp;quot;Timestamp&amp;quot;: &amp;quot;2019-08-29T10:10:00Z&amp;quot;,
&amp;quot;Average&amp;quot;: 84.48684210526316,
&amp;quot;Unit&amp;quot;: &amp;quot;None&amp;quot;
},
{
&amp;quot;Timestamp&amp;quot;: &amp;quot;2019-08-28T20:10:00Z&amp;quot;,
&amp;quot;Average&amp;quot;: 85.0657894736842,
&amp;quot;Unit&amp;quot;: &amp;quot;None&amp;quot;
},
{
&amp;quot;Timestamp&amp;quot;: &amp;quot;2019-08-29T00:10:00Z&amp;quot;,
&amp;quot;Average&amp;quot;: 84.97368421052632,
&amp;quot;Unit&amp;quot;: &amp;quot;None&amp;quot;
},
{
&amp;quot;Timestamp&amp;quot;: &amp;quot;2019-08-29T14:10:00Z&amp;quot;,
&amp;quot;Average&amp;quot;: 82.57894736842105,
&amp;quot;Unit&amp;quot;: &amp;quot;None&amp;quot;
}
]
}
&lt;/code>&lt;/pre></description></item></channel></rss>