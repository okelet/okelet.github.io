<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AWX | Mis notas</title><link>https://blog.okelet.com/tags/awx/</link><atom:link href="https://blog.okelet.com/tags/awx/index.xml" rel="self" type="application/rss+xml"/><description>AWX</description><generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>es-es</language><lastBuildDate>Sat, 18 Jan 2020 00:00:00 +0000</lastBuildDate><image><url>img/map[gravatar:%!s(bool=false) shape:circle]</url><title>AWX</title><link>https://blog.okelet.com/tags/awx/</link></image><item><title>Configurar Microk8s para usar repositorios de AWS ECR</title><link>https://blog.okelet.com/posts/2020/01/configurar-microk8s-para-usar-repositorios-de-aws-ecr/</link><pubDate>Sat, 18 Jan 2020 00:00:00 +0000</pubDate><guid>https://blog.okelet.com/posts/2020/01/configurar-microk8s-para-usar-repositorios-de-aws-ecr/</guid><description>&lt;p>Continuando con un post anterior de cómo
&lt;a href="https://blog.okelet.com/posts/2019/06/probando-ansible-awx-con-microk8s/">probar Ansible AWX con Microk8s&lt;/a> (en AWS EC2). Bueno, pues resulta que me creé una imagen personalizada para el contener &lt;code>awx_task&lt;/code> para instalar una serie de librerías y comandos que necesitaba para lanzar unos playbooks; el fichero &lt;code>Dockerfile&lt;/code> es similar a éste:&lt;/p>
&lt;pre>&lt;code class="language-text">FROM ansible/awx_task:9.1.1
# Switch user to become root
USER 0
# Additional software
RUN cd &amp;amp;&amp;amp; \
set -x &amp;amp;&amp;amp; \
dnf install -y nmap-ncat htop &amp;amp;&amp;amp; \
dnf clean all
# Ansible venv additional dependencies
RUN cd &amp;amp;&amp;amp; \
source /var/lib/awx/venv/ansible/bin/activate &amp;amp;&amp;amp; \
umask 0022 &amp;amp;&amp;amp; \
pip install --upgrade pypsrp pysocks &amp;amp;&amp;amp; \
deactivate
# Restore the original user
# https://github.com/ansible/awx/blob/devel/installer/roles/image_build/templates/Dockerfile.task.j2
USER 1000
&lt;/code>&lt;/pre>
&lt;p>Y me creé un repositorio en
&lt;a href="https://aws.amazon.com/es/ecr/" target="_blank" rel="noopener">AWS ECR&lt;/a>. Después generé la imagen y la subí al repositorio (siendo &lt;code>xxxxxxxxxxx&lt;/code> el ID de la cuenta de AWS):&lt;/p>
&lt;pre>&lt;code class="language-bash">$(aws ecr get-login --no-include-email)
docker build --force-rm --pull --no-cache -t xxxxxxxxxxx.dkr.ecr.eu-west-1.amazonaws.com/ansible/awx_task:9.1.1 .
docker push xxxxxxxxxxx.dkr.ecr.eu-west-1.amazonaws.com/ansible/awx_task:9.1.1
&lt;/code>&lt;/pre>
&lt;p>Tras esto modifiqué el fichero de inventario que usa el instalador de AWX para hacer referencia a la imagen que acabo de subir y crear.&lt;/p>
&lt;pre>&lt;code class="language-yaml">kubernetes_task_image=xxxxxxxxxxx.dkr.ecr.eu-west-1.amazonaws.com/ansible/awx_task
&lt;/code>&lt;/pre>
&lt;p>Pero cuando el cluster de Kubernetes intenta obtener la imagen para crear el pod, se queda en estado &lt;code>ErrImagePull&lt;/code> con el mensaje:&lt;/p>
&lt;pre>&lt;code class="language-text"> Normal Pulling 2s (x3 over 46s) kubelet, pcjuan Pulling image &amp;quot;xxxxxxxxxxx.dkr.ecr.eu-west-1.amazonaws.com/ansible/awx_task:9.1.1&amp;quot;
Warning Failed 2s (x3 over 45s) kubelet, pcjuan Failed to pull image &amp;quot;xxxxxxxxxxx.dkr.ecr.eu-west-1.amazonaws.com/ansible/awx_task:9.1.1&amp;quot;: rpc error: code = Unknown desc = failed to resolve image &amp;quot;xxxxxxxxxxx.dkr.ecr.eu-west-1.amazonaws.com/ansible/awx_task:9.1.1&amp;quot;: no available registry endpoint: unexpected status code https://xxxxxxxxxxx.dkr.ecr.eu-west-1.amazonaws.com/v2/ansible/awx_task/manifests/9.1.1: 401 Unauthorized
Warning Failed 2s (x3 over 45s) kubelet, pcjuan Error: ErrImagePull
&lt;/code>&lt;/pre>
&lt;p>Esto se debe a que Kubernetes no tiene las credenciales necesarias para acceder al repositorio. Pero después de investigar, es fácil solucionarlo. Lo primero que tenemos que hacer es crear un &lt;code>cronjob&lt;/code> en Kubernetes (lo haremos con un crojob porque realmente lo que usa Docker es un token, que tiene caducidad, y hay que renovarlo cada cierto tiempo), para que haga login en el repositorio, y cree una credencial para obtener de forma correcta la imagen; para esto, crearemos un fichero llamado &lt;code>ecr-cred-refresh.yml&lt;/code> con el siguiente contenido:&lt;/p>
&lt;pre>&lt;code class="language-yaml">apiVersion: batch/v1beta1
kind: CronJob
metadata:
name: ecr-cred-helper
spec:
concurrencyPolicy: Allow
schedule: 0 */6 * * *
failedJobsHistoryLimit: 1
successfulJobsHistoryLimit: 3
suspend: false
jobTemplate:
spec:
template:
spec:
containers:
- command:
- /bin/sh
- -c
- |-
NAMESPACE=awx
SERVICE_ACCOUNT=awx
ACCOUNT=$(aws sts get-caller-identity --query 'Account' --output text)
REGION=$(curl -s http://169.254.169.254/latest/dynamic/instance-identity/document | python -c &amp;quot;import json,sys; print(json.loads(sys.stdin.read())['region'])&amp;quot;)
SECRET_NAME=${REGION}-ecr-registry
EMAIL=anymail.doesnt.matter@email.com
TOKEN=$(aws ecr get-login --region ${REGION} --registry-ids ${ACCOUNT} | cut -d' ' -f6)
echo &amp;quot;ENV variables setup done.&amp;quot;
kubectl -n ${NAMESPACE} delete secret --ignore-not-found $SECRET_NAME
kubectl -n ${NAMESPACE} create secret docker-registry $SECRET_NAME \
--docker-server=https://${ACCOUNT}.dkr.ecr.${REGION}.amazonaws.com \
--docker-username=AWS \
--docker-password=&amp;quot;${TOKEN}&amp;quot; \
--docker-email=&amp;quot;${EMAIL}&amp;quot;
echo &amp;quot;Secret created by name $SECRET_NAME&amp;quot;
kubectl -n ${NAMESPACE} patch serviceaccount ${SERVICE_ACCOUNT} -p '{&amp;quot;imagePullSecrets&amp;quot;:[{&amp;quot;name&amp;quot;:&amp;quot;'$SECRET_NAME'&amp;quot;}]}'
echo &amp;quot;All done.&amp;quot;
image: odaniait/aws-kubectl:latest
imagePullPolicy: IfNotPresent
name: ecr-cred-helper
resources: {}
securityContext:
capabilities: {}
terminationMessagePath: /dev/termination-log
terminationMessagePolicy: File
dnsPolicy: Default
hostNetwork: true
restartPolicy: Never
schedulerName: default-scheduler
securityContext: {}
terminationGracePeriodSeconds: 30
&lt;/code>&lt;/pre>
&lt;p>En el fichero anterior, dependiendo de nuestra configuración particular, podremos cambiar el valor de las variables &lt;code>NAMESPACE&lt;/code> y &lt;code>SERVICE_ACCOUNT&lt;/code>, y también especificar manualmente las variables &lt;code>ACCOUNT&lt;/code> y &lt;code>REGION&lt;/code> si no queremos que el script las auto-detecte porque usamos otras en concreto.&lt;/p>
&lt;p>Básicamente, lo que hace esto, es crear un trabajo de cron, que lanza un contenedor y ejecuta el script en Bash definido en la especificación del pod. En resumen:&lt;/p>
&lt;ul>
&lt;li>Obtiene las credenciales de acceso a ECR utilizando la cli de AWS&lt;/li>
&lt;li>Elimina, si existe, el secreto llamado &lt;code>${REGION}-ecr-registry&lt;/code>&lt;/li>
&lt;li>Lo crea de nuevo, con el token obtenido de ECR&lt;/li>
&lt;li>Actualiza la service account de AWX indicándole que para obtener las imágenes (&lt;code>imagePullSecrets&lt;/code>) tiene usar las credenciales del secreto recién creado&lt;/li>
&lt;/ul>
&lt;p>Tras esto, importamos la definición del job en Kubernetes:&lt;/p>
&lt;pre>&lt;code class="language-bash">kubectl -n awx apply -f ecr-cred-refresh.yml
&lt;/code>&lt;/pre>
&lt;p>Este job se ejecuta cada 6 horas; si queremos forzar la ejecución, podemos hacerlo con los siguientes comandos:&lt;/p>
&lt;pre>&lt;code class="language-bash">JOB_NAME=&amp;quot;manual-$(date --utc +%Y%m%d-%H%M%S)&amp;quot;
kubectl -n awx create job --from=cronjob/ecr-cred-helper ${JOB_NAME}
kubectl -n awx wait --for=condition=complete job.batch/${JOB_NAME}
kubectl -n awx logs job.batch/${JOB_NAME}
&lt;/code>&lt;/pre>
&lt;p>Pero esto por sí solo no nos vale&amp;hellip; porque ¿dónde le decimos las crendenciales para acceder a AWS (es decir, para que desde dentro del cronjob se pueda hacer &lt;code>aws ecr get-login&lt;/code>)? Es decir, el access key y el secret. Para esto, no le pasaremos una key y un secret, sino que crearemos un rol y se lo asignaremos a la instancia EC2 de AWS donde estemos ejecutando Microk8s. El rol debe tener una policy que permita a la instancia acceder al repositorio; podemos usar la policy predefinida &lt;code>AmazonEC2ContainerRegistryReadOnly&lt;/code> o crear una manualmente.&lt;/p>
&lt;p>Tras crear el rol y la policy, y asignar el rol a la instancia, podemos ejecutar manualmente el &lt;code>cronjob&lt;/code>, y ejecutar de nuevo el instalador de AWX, que ya debería obtener la imagen de Docker sin problemas.&lt;/p>
&lt;p>Comandos útiles:&lt;/p>
&lt;pre>&lt;code class="language-bash"># Ver información de la service account de awx
kubectl -n awx describe serviceaccounts awx
# Ver información de los secretos (cuándo se actualizó/obtuvo el token por última vez)
kubectl -n awx get secrets
&lt;/code>&lt;/pre>
&lt;p>Probar manualmente el script:&lt;/p>
&lt;pre>&lt;code class="language-bash">kubectl run -i --tty --rm debug --image=odaniait/aws-kubectl:latest --restart=Never -- sh
kubectl run --generator=run-pod/v1 -n awx --rm -i --tty compass-tmp --image=odaniait/aws-kubectl:latest -- sh
&lt;/code>&lt;/pre>
&lt;p>Referencias:&lt;/p>
&lt;ul>
&lt;li>
&lt;a href="https://medium.com/@damitj07/how-to-configure-and-use-aws-ecr-with-kubernetes-rancher2-0-6144c626d42c" target="_blank" rel="noopener">How to configure and use AWS ECR with kubernetes &amp;amp; Rancher2.0&lt;/a>&lt;/li>
&lt;/ul></description></item><item><title>Probando Ansible AWX con MicroK8s</title><link>https://blog.okelet.com/posts/2019/06/probando-ansible-awx-con-microk8s/</link><pubDate>Wed, 19 Jun 2019 00:00:00 +0000</pubDate><guid>https://blog.okelet.com/posts/2019/06/probando-ansible-awx-con-microk8s/</guid><description>&lt;p>AVISO: Post largo (intro a Ansible, AWX, MicroK8s)&lt;/p>
&lt;p>Actualización 2020-01-14: Actualizado a
&lt;a href="https://groups.google.com/forum/#!topic/awx-project/aYYtuAuHMzY" target="_blank" rel="noopener">Ansible AWX 9.1.1&lt;/a>&lt;/p>
&lt;p>Ansible (&lt;em>/ánsibol/&lt;/em>) es el gestor de configuración de moda, y por méritos propios. Aunque no es perfecto (en determinadas ocasiones se puede preferir un modelo cliente/servidor en lugar de una conexión SSH &lt;em>ad-hoc&lt;/em>), ofrece una buena combinación entre funcionalidad y simplicidad. Siempre y cuando tengamos conectividad SSH con la máquina a gestionar (o no, a través de
&lt;a href="https://docs.aws.amazon.com/es_es/quickstart/latest/linux-bastion/architecture.html" target="_blank" rel="noopener">bastiones&lt;/a>), en el caso de equipos Linux, o conectividad WinRM o o PSRP para equipos Windows, podremos realizar infinidad de acciones o tareas sobre las máquinas a gestionar.&lt;/p>
&lt;p>Uno de los problemas de Ansible (hablando correctamente,
&lt;a href="https://www.ansible.com/blog/red-hat-ansible-automation-engine-vs-tower" target="_blank" rel="noopener">Ansible Engine&lt;/a>) es que no tiene una forma de ejecutar de forma automatizada playbooks, para mantener la configuración sincronizada de forma periódica, ejecutar tareas planificadas o incluso auto-provisionar equipos. Aquí es donde entra Ansible Tower, que es la versión con soporte de
&lt;a href="https://github.com/ansible/awx" target="_blank" rel="noopener">Ansible AWX&lt;/a>, al estilo de lo que Red Hat hace con Wildfly y JBoss. Ansible Tower/AWX en básicamente una API REST con una interfaz web que se comunica con ella. Utilizando esta API, se pueden definir inventarios, credenciales, equipos, plantillas de trabajo, flujos de trabajo, etc. así como asignar permisos por usarios/grupos mediante su sistema RBAC.&lt;/p>
&lt;p>He de reconocer que al principio cuesta un poco, pero cuando se le pilla el truco, uno se da cuenta de lo potente que es. Pero lo que no me explico es la complejidad de instalación del software. Creo que Red Hat se está empeñando en poner las cosas difíciles a quienes usan sus productos sin suscripción (que al final son los que en gran medida depuran el software, contribuyen de forma gratuita, etc.); en este caso, se nos obliga a hacer una instalación mediante Docker, que aunque está de moda, que lo veo muy bien, creo que deberían dar alternativas (que sí que las dan con la versión con soporte, por lo que impedimentos técnicos no los hay, simplemente es intencionalidad). Para la versión libre (AWX) se soportan los siguientes
&lt;a href="https://github.com/ansible/awx/blob/devel/INSTALL.md" target="_blank" rel="noopener">métodos de instalación&lt;/a>:&lt;/p>
&lt;ul>
&lt;li>Openshift (claramente enfocado a utilizar un stack completo de Red Hat)&lt;/li>
&lt;li>Docker Compose&lt;/li>
&lt;li>Kubernetes&lt;/li>
&lt;/ul>
&lt;p>En cambio, para Tower, la versión con soporte, es básicamente un script de instalación, que la verdad no he probado, aunque me imagino que lo que hace es provisionar los nodos con el software necesario, a la antigua usanza (no sé si por debajo creará un cluster de K8s u Openshift, o directamente lo hace sobre el sistema operativo).&lt;/p>
&lt;p>Básicamente, la forma de instalación de AWX es crear una serie de contenedores en el orquestador en cuestión (AWX task, AWX web, RabbitMQ, Postgres, Memcached).&lt;/p>
&lt;p>Con ideas de probar AWX para un proyecto interno, empecé a analizar las 3 opciones de instalación; la primera de ellas, Openshift, la descarté desde el principio por ser una tecnología no muy extendida, en favor, en todo caso, de Kubernetes. Ya que esto era una
&lt;a href="https://es.wikipedia.org/wiki/Prueba_de_concepto" target="_blank" rel="noopener">PoC&lt;/a>, no quería complicarme mucho con Kubernetes, por lo que empecé a probar con Docker Compose, pero a la hora de escalar, lanzando la instalación en varios nodos, me di cuenta de que el modo de funcionar de AWX requiere un cluster de
&lt;a href="https://www.rabbitmq.com/" target="_blank" rel="noopener">RabbitMQ&lt;/a>, que es difícil de configurar dinámicamente con Docker Compose. Con Kubernetes y su
&lt;a href="https://github.com/ansible/awx/blob/devel/installer/roles/kubernetes/templates/deployment.yml.j2#L38" target="_blank" rel="noopener">&amp;ldquo;magia&amp;rdquo;&lt;/a> hace que el cluster de RabbitMQ se configure y escale automáticamente.&lt;/p>
&lt;p>Siendo mi única opción Kubernetes, no quería montarme un cluster por mi cuenta, ni tener que montar un cluster de EKS, que
&lt;a href="https://aws.amazon.com/es/eks/pricing/" target="_blank" rel="noopener">de base ya son 144$ al mes&lt;/a> más los nodos de computación, al final tuve que buscar alternativas más simples.&lt;/p>
&lt;p>Mi primera intención fue probar
&lt;a href="https://kubernetes.io/es/docs/tasks/tools/install-minikube/" target="_blank" rel="noopener">Minikube&lt;/a> en mi máquina local, pero cada pod de AWX consume 6 GB de RAM, por lo que mínimo a la MV de Minikube le tenía que dar 7 GB, y teniendo mi portátil 8 GB, murió varias veces en el intento&amp;hellip; Me planteé montar Minikube en una instancia EC2, pero esto sería montar Virtualbox, sobre un entorno ya virtualizado (EC2), y sobre el que correría Kubernetes&amp;hellip; Aunque factible, me parecía un poco engorroso. Así que gracias a mi compañero Roque, que me recordó la existencia de
&lt;a href="https://microk8s.io/" target="_blank" rel="noopener">MicroK8s&lt;/a>, me decidí a probar.&lt;/p>
&lt;p>Partiendo de una EC2 con Ubuntu 18.04 limpia, estos son los comandos a ejecutar para montar un entorno de Ansible AWX con MicroK8s (forzamos la versión 1.15, ya que AWX no es compatible con una versión mayor, por ahora):&lt;/p>
&lt;pre>&lt;code class="language-bash">sudo snap refresh microk8s --channel 1.15/stable
sudo snap install helm --channel=2.16/stable --classic
(grep &amp;quot;^--allow-privileged$&amp;quot; /var/snap/microk8s/current/args/kube-apiserver &amp;gt; /dev/null) || (echo &amp;quot;--allow-privileged&amp;quot; | sudo tee -a /var/snap/microk8s/current/args/kube-apiserver)
(grep &amp;quot;^--allow-privileged$&amp;quot; /var/snap/microk8s/current/args/kubelet &amp;gt; /dev/null) || (echo &amp;quot;--allow-privileged&amp;quot; | sudo tee -a /var/snap/microk8s/current/args/kubelet)
sudo microk8s.stop
sudo microk8s.start
microk8s.enable ingress
microk8s.enable dns
microk8s.enable storage
sudo snap alias microk8s.kubectl kubectl
microk8s.config &amp;gt; $HOME/.kube/config
helm init
&lt;/code>&lt;/pre>
&lt;p>
&lt;a href="https://helm.sh/" target="_blank" rel="noopener">Helm&lt;/a> es necesario para instalación de Postgres; si vamos a utilizar una BBDD externa, no es necesario.&lt;/p>
&lt;p>Tras esto, ya tenemos el entorno de MicroK8s disponible; ahora nos bajamos AWX y lo configuramos:&lt;/p>
&lt;pre>&lt;code class="language-bash"># Actualizar e instalar dependencias mínimas
sudo apt update
sudo apt upgrade -y
sudo apt install -y python3-pip vim
pip3 install docker docker-compose --user
# Instalar Ansible, necesario para instalar AWX
sudo add-apt-repository ppa:ansible/ansible -y
sudo apt update
sudo apt install -y ansible
# Nos bajamos la release 9.1.1 de AWX
curl -sLO https://github.com/ansible/awx/archive/9.1.1.tar.gz
tar zxf 9.1.1.tar.gz
cd awx-9.1.1/installer
cp -a inventory{,.original}
# Configuramos el fichero de inventario para que use Kubernetes
sed -i -e 's/#* *kubernetes_context.*/kubernetes_context=microk8s/' inventory
sed -i -e 's/#* *kubernetes_namespace.*/kubernetes_namespace=awx/' inventory
# Y lanzamos la instalación
ansible-playbook -i inventory install.yml
&lt;/code>&lt;/pre>
&lt;p>Variables interesantes en el fichero &lt;code>inventory&lt;/code>:&lt;/p>
&lt;ul>
&lt;li>&lt;code>kubernetes_context&lt;/code>: el contexto del cliente de Kubernetes que usaremos para conectarnos al cluster; para MicroK8s, en general será &lt;code>microk8s&lt;/code>.&lt;/li>
&lt;li>&lt;code>kubernetes_namespace&lt;/code>: el &lt;em>namespace&lt;/em> del cluster de Kubernetes que se usará para crear todos los elementos de AWX; por defecto es &lt;code>awx&lt;/code>.&lt;/li>
&lt;li>&lt;code>kubernetes_deployment_name&lt;/code>: es un prefijo que se usa para generar los nombres de los recursos dentro del &lt;em>namespace&lt;/em>; por defecto es &lt;code>awx&lt;/code>.&lt;/li>
&lt;li>&lt;code>pg_hostname&lt;/code>: es el host remoto donde debemos tener instalado un servidor de Postgres; si esta variable está comentada, el instalador creará un servidor de Postgres en Kubernetes usando Helm; si está definida, se usará el servidor indicado (habrá que configurar adecuadamente el resto de parámetros de conexión a la BBDD: &lt;code>pg_username&lt;/code>, &lt;code>pg_password&lt;/code>, &lt;code>pg_database&lt;/code>, etc.).&lt;/li>
&lt;/ul>
&lt;p>También se pueden especificar las siguientes variables para indicar imágenes y versiones alternativas a las oficiales (por ejemplo, si hemos creado unas propias para añadir software, etc.):&lt;/p>
&lt;ul>
&lt;li>&lt;code>kubernetes_task_version&lt;/code> (por defecto: &lt;code>9.1.1&lt;/code>)&lt;/li>
&lt;li>&lt;code>kubernetes_task_image&lt;/code> (por defecto: &lt;code>ansible/awx_task&lt;/code>)&lt;/li>
&lt;li>&lt;code>kubernetes_web_version&lt;/code> (por defecto: &lt;code>9.1.1&lt;/code>)&lt;/li>
&lt;li>&lt;code>kubernetes_web_image&lt;/code> (por defecto: &lt;code>ansible/awx_web&lt;/code>)&lt;/li>
&lt;/ul>
&lt;p>Esto nos creará un namespace llamado &lt;code>awx&lt;/code> en MicroK8s, y desplegará en él 2 &lt;code>statefulsets&lt;/code>: 1 para Postgres y uno para AWX. Cada &lt;code>statefulset/pod&lt;/code> de AWX contiene los siguientes contenedores:&lt;/p>
&lt;ul>
&lt;li>memcached&lt;/li>
&lt;li>rabbitmq&lt;/li>
&lt;li>awx-celery (awx_task)&lt;/li>
&lt;li>awx-web&lt;/li>
&lt;/ul>
&lt;p>Cada vez que se escala el &lt;code>statefulset&lt;/code> se crean estos 4 contenedores. Gracias al plugin
&lt;a href="https://github.com/rabbitmq/rabbitmq-peer-discovery-k8s" target="_blank" rel="noopener">&lt;code>rabbitmq_peer_discovery_k8s&lt;/code>&lt;/a> (
&lt;a href="https://github.com/ansible/awx/blob/devel/installer/roles/kubernetes/templates/deployment.yml.j2#L38" target="_blank" rel="noopener">aquí&lt;/a> se puede ver fichero YAML de configuración) los contenedores de rabbitmq forman un cluster de forma automática.&lt;/p>
&lt;p>Para volver a empezar desde 0, tenemos 2 posibilidades; o bien borrar el &lt;em>namespace&lt;/em>:&lt;/p>
&lt;pre>&lt;code class="language-bash">kubectl delete namespaces awx
&lt;/code>&lt;/pre>
&lt;p>O bien con el comando &lt;code>microk8s.reset&lt;/code>, aunque con este comando, frecuentemente se queda &amp;ldquo;colgado&amp;rdquo;:&lt;/p>
&lt;pre>&lt;code class="language-bash">microk8s.reset
&lt;/code>&lt;/pre>
&lt;p>Después del reset, es necesario volver a configurar los complementos (dns, storage, ingress), y configurar el cliente:&lt;/p>
&lt;pre>&lt;code class="language-bash">microk8s.enable ingress
microk8s.enable dns
microk8s.enable storage
sudo snap alias microk8s.kubectl kubectl
microk8s.config &amp;gt; $HOME/.kube/config
helm init
&lt;/code>&lt;/pre>
&lt;p>Y podemos lanzar de nuevo la instalación:&lt;/p>
&lt;pre>&lt;code class="language-bash">ansible-playbook -i inventory install.yml
&lt;/code>&lt;/pre>
&lt;p>Si por delante del servidor vamos a poner un balanceador (por ejemplo, un ELB o ALB), debemos configurar el &lt;code>ingress&lt;/code> de Nginx para que reenvíe las cabeceras &lt;code>X-Forwarded-*&lt;/code>:&lt;/p>
&lt;pre>&lt;code class="language-bash">kubectl -n default edit configmaps nginx-load-balancer-microk8s-conf
&lt;/code>&lt;/pre>
&lt;p>Añadiendo/modificando la sección data con este valor:&lt;/p>
&lt;pre>&lt;code class="language-yaml">data:
use-forwarded-headers: &amp;quot;true&amp;quot;
&lt;/code>&lt;/pre>
&lt;p>Esto es necesario, por ejemplo, si se usa un balanceador con HTTPS, y configuramos la autentificación de Azure, ya que sin el reenvío de estas cabeceras, AWX se cree que vamos por HTTP en lugar de HTTPS, y la URL de callback para el login de Azure se genera incorrectamente.&lt;/p>
&lt;p>Una vez realizados los pasos de la instalación, lo único que nos queda es acceder a la aplicación, usando el puerto 80 de la máquina, por ejemplo,
&lt;a href="http://localhost" target="_blank" rel="noopener">http://localhost&lt;/a>, que es donde publica los servicios el &lt;em>ingress controller&lt;/em> de nginx.&lt;/p></description></item></channel></rss>